var documenterSearchIndex = {"docs":
[{"location":"api/Optimisation/#API:-Turing.Optimisation","page":"Optimisation","title":"API: Turing.Optimisation","text":"","category":"section"},{"location":"api/Optimisation/#DynamicPPL.InitFromParams","page":"Optimisation","title":"DynamicPPL.InitFromParams","text":"InitFromParams(\n    m::ModeResult,\n    fallback::Union{AbstractInitStrategy,Nothing}=InitFromPrior()\n)\n\nInitialize a model from the parameters stored in a ModeResult. The fallback is used if some parameters are missing from the ModeResult.\n\n\n\n\n\n","category":"type"},{"location":"api/Optimisation/#Turing.Optimisation.InitWithConstraintCheck","page":"Optimisation","title":"Turing.Optimisation.InitWithConstraintCheck","text":"InitWithConstraintCheck(lb, ub, actual_strategy) <: AbstractInitStrategy\n\nInitialise parameters with actual_strategy, but check that the initialised parameters satisfy any bounds in lb and ub.\n\n\n\n\n\n","category":"type"},{"location":"api/Optimisation/#Turing.Optimisation.MAP","page":"Optimisation","title":"Turing.Optimisation.MAP","text":"MAP <: ModeEstimator\n\nConcrete type for maximum a posteriori estimation.\n\n\n\n\n\n","category":"type"},{"location":"api/Optimisation/#Turing.Optimisation.MLE","page":"Optimisation","title":"Turing.Optimisation.MLE","text":"MLE <: ModeEstimator\n\nConcrete type for maximum likelihood estimation.\n\n\n\n\n\n","category":"type"},{"location":"api/Optimisation/#Turing.Optimisation.ModeEstimator","page":"Optimisation","title":"Turing.Optimisation.ModeEstimator","text":"ModeEstimator\n\nAn abstract type to mark whether mode estimation is to be done with maximum a posteriori (MAP) or maximum likelihood estimation (MLE).\n\n\n\n\n\n","category":"type"},{"location":"api/Optimisation/#Turing.Optimisation.ModeResult","page":"Optimisation","title":"Turing.Optimisation.ModeResult","text":"ModeResult{\n    E<:ModeEstimator,\n    P<:AbstractDict{<:VarName,<:Any}\n    LP<:Real,\n    L<:DynamicPPL.LogDensityFunction,\n    O<:Any,\n}\n\nA wrapper struct to store various results from a MAP or MLE estimation.\n\nFields\n\nestimator::Turing.Optimisation.ModeEstimator: The type of mode estimation (MAP or MLE).\nparams::AbstractDict{<:AbstractPPL.VarName}: Dictionary of parameter values. These values are always provided in unlinked space,     even if the optimisation was run in linked space.\nlp::Real: The final log likelihood or log joint, depending on whether MAP or MLE was run.     Note that this is the actual log probability of the parameters, i.e., not negated;     we do need a negated log probability to run the optimisation itself (since it is a     maximisation), but this is handled in a way that is entirely transparent to the user.\nlinked::Bool: Whether the optimisation was done in a transformed space.\nldf::LogDensityFunction: The LogDensityFunction used to calculate the output. Note that this LogDensityFunction     calculates the actual (non-negated) log density. It should hold that m.lp ==     LogDensityProblems.logdensity(m.ldf, m.optim_result.u).\noptim_result::Any: The stored optimiser results.\n\n\n\n\n\n","category":"type"},{"location":"api/Optimisation/#Turing.Optimisation.ModeResult-Tuple{LogDensityFunction, SciMLBase.OptimizationSolution, Bool, Turing.Optimisation.ModeEstimator}","page":"Optimisation","title":"Turing.Optimisation.ModeResult","text":"ModeResult(\n    log_density::DynamicPPL.LogDensityFunction,\n    solution::SciMLBase.OptimizationSolution,\n    linked::Bool,\n    estimator::ModeEstimator,\n)\n\nCreate a ModeResult for a given log_density objective and a solution given by solve. The linked argument indicates whether the optimization was done in a transformed space.\n\nOptimization.solve returns its own result type. This function converts that into the richer format of ModeResult. It also takes care of transforming them back to the original parameter space in case the optimization was done in a transformed space.\n\n\n\n\n\n","category":"method"},{"location":"api/Optimisation/#StatsAPI.coeftable-Tuple{Turing.Optimisation.ModeResult}","page":"Optimisation","title":"StatsAPI.coeftable","text":"StatsBase.coeftable(m::ModeResult; level::Real=0.95, numerrors_warnonly::Bool=true)\n\nReturn a table with coefficients and related statistics of the model. level determines the level for confidence intervals (by default, 95%).\n\nIn case the numerrors_warnonly argument is true (the default) numerical errors encountered during the computation of the standard errors will be caught and reported in an extra \"Error notes\" column.\n\n\n\n\n\n","category":"method"},{"location":"api/Optimisation/#StatsAPI.informationmatrix-Tuple{Turing.Optimisation.ModeResult}","page":"Optimisation","title":"StatsAPI.informationmatrix","text":"StatsBase.informationmatrix(\n    m::ModeResult;\n    adtype::ADTypes.AbstractADType=ADTypes.AutoForwardDiff()\n)\n\nCalculate the Fisher information matrix for the mode result m. This is the negative Hessian of the log-probability at the mode.\n\nThe Hessian is calculated using automatic differentiation with the specified adtype. By default this is ADTypes.AutoForwardDiff(). In general, however, it may be more efficient to use forward-over-reverse AD when the model has many parameters. This can be specified using DifferentiationInterface.SecondOrder(outer, inner); please consult the DifferentiationInterface.jl documentation for more details.\n\n\n\n\n\n","category":"method"},{"location":"api/Optimisation/#Turing.Optimisation.estimate_mode","page":"Optimisation","title":"Turing.Optimisation.estimate_mode","text":"estimate_mode(\n    [rng::Random.AbstractRNG,]\n    model::DynamicPPL.Model,\n    estimator::ModeEstimator,\n    solver=OptimizationOptimJL.LBFGS();\n    link::Bool=true,\n    initial_params=DynamicPPL.InitFromPrior(),\n    lb::Union{NamedTuple,AbstractDict{<:VarName,<:Any}}=(;),\n    ub::Union{NamedTuple,AbstractDict{<:VarName,<:Any}}=(;),\n    adtype::AbstractADType=AutoForwardDiff(),\n    check_model::Bool=true,\n    check_constraints_at_runtime::Bool=true,\n    kwargs...,\n)\n\nFind the mode of the probability distribution of a model.\n\nUnder the hood this function constructs a LogDensityFunction and calls Optimization.solve on it.\n\nNote that the optimisation interface that Turing exposes is a more high-level interface which is tailored towards probabilistic modelling, so not every option available in Optimization.jl is supported here. In particular, Turing's optimisation interface allows you to:\n\nProvide initial parameters, lower bounds, and upper bounds as mappings of VarNames to values in original (unlinked space).\nChoose whether to run the optimisation in linked or unlinked space (by default linked). Linked space means that parameters are transformed to unconstrained Euclidean space, meaning that you can avoid hard edges in the optimisation landscape (i.e., logpdf suddenly dropping to -Inf outside the support of a variable). It also avoids cases where parameters may not be independent, e.g., x ~ Dirichlet(...) where the components of x must sum to 1. Optimisation in linked space is enabled by default.\n\nTuring is responsible for 'translating' these user-friendly specifications into vectorised forms (of initial parameters, lower bounds, and upper bounds) that Optimization.jl can work with.\n\nHowever, there are cases where this translation can fail or otherwise be ill-defined (specifically when considering constraints). For example, recall that constraints are supplied in unlinked space, but the optimisation is run by default in linked space. Sometimes it is possible to translate constraints from unlinked space to linked space: for example, for x ~ Beta(2, 2), lower bounds in unlinked space can be translated to lower bounds in linked space via the logit transform (specificallly, by calling to_linked_vec_transform(Beta(2, 2)).\n\nHowever, if a user supplies a constraint on a Dirichlet variable, there is no well-defined mapping of unlinked constraints to linked space. In such cases, Turing will throw an error (although you can still run in unlinked space). Generic, non-box constraints are also not possible to correctly support, so Turing's optimisation interface refuses to support them.\n\nSee https://github.com/TuringLang/Turing.jl/issues/2634 for more discussion on the interface and what it supports.\n\nIf you need these capabilities, we suggest that you create your own LogDensityFunction and call Optimization.jl directly on it.\n\nArguments\n\nrng::Random.AbstractRNG: an optional random number generator. This is used only for parameter initialisation; it does not affect the actual optimisation process.\nmodel::DynamicPPL.Model: The model for which to estimate the mode.\nestimator::ModeEstimator: Can be either MLE() for maximum likelihood estimation or MAP() for maximum a posteriori estimation.\nsolver=OptimizationOptimJL.LBFGS(): The optimization algorithm to use. The default solver is L-BFGS, which is a good general-purpose solver that supports box constraints. You can also use any solver supported by Optimization.jl. \n\nKeyword arguments\n\nlink::Bool=true: if true, the model parameters are transformed to an unconstrained space for the optimisation. This is generally recommended as it avoids hard edges (i.e., returning a probability of Inf outside the support of the parameters), which can lead to NaN's or incorrect results. Note that the returned parameter values are always in the original (unlinked) space, regardless of whether link is true or false.\ninitial_params::DynamicPPL.AbstractInitStrategy=DynamicPPL.InitFromPrior(): an initialisation strategy for the parameters. By default, parameters are initialised by generating from the prior. The initialisation strategy will always be augmented by any contraints provided via lb and ub, in that the initial parameters will be guaranteed to lie within the provided bounds.\nlb::Union{NamedTuple,AbstractDict{<:VarName,<:Any}}=(;): a mapping from variable names to lower bounds for the optimisation. The bounds should be provided in the original (unlinked) space. Not all constraints are supported by Turing's optimisation interface. See details above.\nub::Union{NamedTuple,AbstractDict{<:VarName,<:Any}}=(;): a mapping from variable names to upper bounds for the optimisation. The bounds should be provided in the original (unlinked) space. Not all constraints are supported by Turing's optimisation interface. See details above.\nadtype::AbstractADType=AutoForwardDiff(): The automatic differentiation backend to use.\ncheck_model::Bool=true: if true, the model is checked for potential errors before optimisation begins.\ncheck_constraints_at_runtime::Bool=true: if true, the constraints provided via lb  and ub are checked at each evaluation of the log probability during optimisation (even  though Optimization.jl already has access to these constraints). This can be useful in a  very specific situation: consider a model where a variable has a dynamic support, e.g.  y ~ truncated(Normal(); lower=x), where x is another variable in the model. In this  case, if the model is run in linked space, then the box constraints that Optimization.jl  sees may not always be correct, and y may go out of its intended bounds due to changes  in x. Enabling this option will ensure that such violations are caught and an error  thrown. This is very cheap to do, but if you absolutely need to squeeze out every last  bit of performance and you know you will not be hitting the edge case above, you can  disable this check.\n\nAny extra keyword arguments are passed to Optimization.solve.\n\n\n\n\n\n","category":"function"},{"location":"api/Optimisation/#Turing.Optimisation.get_vectorised_params-Tuple{Turing.Optimisation.ModeResult}","page":"Optimisation","title":"Turing.Optimisation.get_vectorised_params","text":"get_vectorised_params(m::ModeResult)\n\nGenerates a vectorised form of the optimised parameters stored in the ModeResult, along with the corresponding variable names. These parameters correspond to unlinked space.\n\nThis function returns two vectors: the first contains the variable names, and the second contains the corresponding values.\n\n\n\n\n\n","category":"method"},{"location":"api/Optimisation/#Turing.Optimisation.make_optim_bounds_and_init-Union{Tuple{Tlink}, Tuple{Random.AbstractRNG, LogDensityFunction{Tlink}, DynamicPPL.AbstractInitStrategy, Union{AbstractDict{<:AbstractPPL.VarName}, NamedTuple}, Union{AbstractDict{<:AbstractPPL.VarName}, NamedTuple}}} where Tlink","page":"Optimisation","title":"Turing.Optimisation.make_optim_bounds_and_init","text":"make_optim_bounds_and_init(\n    rng::Random.AbstractRNG,\n    ldf::LogDensityFunction{Tlink},\n    initial_params::AbstractInitStrategy,\n    lb::NTOrVNDict,\n    ub::NTOrVNDict,\n) where {Tlink}\n\nGenerate a tuple of (lb_vec, ub_vec, init_vec) which are suitable for directly passing to Optimization.jl. All three vectors returned will be in the unlinked or linked space depending on the value of link.\n\nThe lb and ub arguments, as well as any initial_params provided as InitFromParams, are expected to be in the unlinked space.\n\n\n\n\n\n","category":"method"},{"location":"api/Optimisation/#Turing.Optimisation.maximum_a_posteriori-Tuple{Random.AbstractRNG, DynamicPPL.Model, Vararg{Any}}","page":"Optimisation","title":"Turing.Optimisation.maximum_a_posteriori","text":"maximum_a_posteriori(\n    [rng::Random.AbstractRNG,]\n    model::DynamicPPL.Model,\n    [solver];\n    kwargs...\n)\n\nFind the maximum a posteriori estimate of a model.\n\nThis is a convenience function that calls estimate_mode with MAP() as the estimator. Please see the documentation of Turing.Optimisation.estimate_mode for full details.\n\n\n\n\n\n","category":"method"},{"location":"api/Optimisation/#Turing.Optimisation.maximum_likelihood-Tuple{Random.AbstractRNG, DynamicPPL.Model, Vararg{Any}}","page":"Optimisation","title":"Turing.Optimisation.maximum_likelihood","text":"maximum_likelihood(\n    [rng::Random.AbstractRNG,]\n    model::DynamicPPL.Model,\n    [solver];\n    kwargs...\n)\n\nFind the maximum likelihood estimate of a model.\n\nThis is a convenience function that calls estimate_mode with MLE() as the estimator. Please see the documentation of Turing.Optimisation.estimate_mode for full details.\n\n\n\n\n\n","category":"method"},{"location":"api/Optimisation/#Turing.Optimisation.satisfies_constraints-Tuple{Union{Nothing, Real}, Union{Nothing, Real}, Real, UnivariateDistribution}","page":"Optimisation","title":"Turing.Optimisation.satisfies_constraints","text":"satisfies_constraints(lb, ub, proposed_val, dist)\n\nCheck whether proposed_val satisfies the constraints defined by lb and ub.\n\nThe methods that this function provides therefore dictate what values users can specify for different types of distributions. For example, for UnivariateDistribution, the constraints must be supplied as Real numbers. If other kinds of constraints are given, it will hit the fallback method and an error will be thrown.\n\nThis method intentionally does not handle NaN values as that is left to the optimiser to deal with.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#API:-Turing.Inference","page":"Inference","title":"API: Turing.Inference","text":"","category":"section"},{"location":"api/Inference/#Turing.Inference.CSMC","page":"Inference","title":"Turing.Inference.CSMC","text":"CSMC(...)\n\nEquivalent to PG.\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.ESS","page":"Inference","title":"Turing.Inference.ESS","text":"ESS\n\nElliptical slice sampling algorithm.\n\nExamples\n\njulia> @model function gdemo(x)\n           m ~ Normal()\n           x ~ Normal(m, 0.5)\n       end\ngdemo (generic function with 2 methods)\n\njulia> sample(gdemo(1.0), ESS(), 1_000) |> mean\nMean\n\n│ Row │ parameters │ mean     │\n│     │ Symbol     │ Float64  │\n├─────┼────────────┼──────────┤\n│ 1   │ m          │ 0.824853 │\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.Emcee","page":"Inference","title":"Turing.Inference.Emcee","text":"Emcee(n_walkers::Int, stretch_length=2.0)\n\nAffine-invariant ensemble sampling algorithm.\n\nReference\n\nForeman-Mackey, D., Hogg, D. W., Lang, D., & Goodman, J. (2013). emcee: The MCMC Hammer. Publications of the Astronomical Society of the Pacific, 125 (925), 306. https://doi.org/10.1086/670067\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.ExternalSampler","page":"Inference","title":"Turing.Inference.ExternalSampler","text":"ExternalSampler{Unconstrained,S<:AbstractSampler,AD<:ADTypes.AbstractADType}\n\nRepresents a sampler that does not have a custom implementation of AbstractMCMC.step(rng, ::DynamicPPL.Model, spl).\n\nThe Unconstrained type-parameter is to indicate whether the sampler requires unconstrained space.\n\nFields\n\nsampler::AbstractMCMC.AbstractSampler: the sampler to wrap\nadtype::ADTypes.AbstractADType: the automatic differentiation (AD) backend to use\n\nTuring.jl's interface for external samplers\n\nIf you implement a new MySampler <: AbstractSampler and want it to work with Turing.jl models, there are two options:\n\nDirectly implement the AbstractMCMC.step methods for DynamicPPL.Model. That is to say, implement AbstractMCMC.step(rng::Random.AbstractRNG, model::DynamicPPL.Model, sampler::MySampler; kwargs...) and related methods. This is the most powerful option and is what Turing.jl's in-house samplers do. Implementing this means that you can directly call sample(model, MySampler(), N).\nImplement a generic AbstractMCMC.step method for AbstractMCMC.LogDensityModel (the same signature as above except that model::AbstractMCMC.LogDensityModel). This struct wraps an object that obeys the LogDensityProblems.jl interface, so your step implementation does not need to know anything about Turing.jl or DynamicPPL.jl. To use this with Turing.jl, you will need to wrap your sampler: sample(model, externalsampler(MySampler()), N).\n\nThis section describes the latter.\n\nMySampler must implement the following methods:\n\nAbstractMCMC.step (the main function for taking a step in MCMC sampling; this is documented in AbstractMCMC.jl). This function must return a tuple of two elements, a 'transition' and a 'state'.\nAbstractMCMC.getparams(external_state): How to extract the parameters from the state returned by your sampler (i.e., the second return value of step). For your sampler to work with Turing.jl, this function should return a Vector of parameter values. Note that this function does not need to perform any linking or unlinking; Turing.jl will take care of this for you. You should return the parameters exactly as your sampler sees them.\nAbstractMCMC.getstats(external_state): Extract sampler statistics corresponding to this iteration from the state returned by your sampler (i.e., the second return value of step). For your sampler to work with Turing.jl, this function should return a NamedTuple. If there are no statistics to return, return NamedTuple().\nNote that getstats should not include log-probabilities as these will be recalculated by Turing automatically for you.\n\nNotice that both of these functions take the state as input, not the transition. In other words, the transition is completely useless for the external sampler interface. This is in line with long-term plans for removing transitions from AbstractMCMC.jl and only using states.\n\nThere are a few more optional functions which you can implement to improve the integration with Turing.jl:\n\nAbstractMCMC.requires_unconstrained_space(::MySampler): If your sampler requires unconstrained space, you should return true. This tells Turing to perform linking on the VarInfo before evaluation, and ensures that the parameter values passed to your sampler will always be in unconstrained (Euclidean) space.\nTuring.Inference.isgibbscomponent(::MySampler): If you want to disallow your sampler from a component in Turing's Gibbs sampler, you should make this evaluate to false. Note that the default is true, so you should only need to implement this in special cases.\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.Gibbs","page":"Inference","title":"Turing.Inference.Gibbs","text":"Gibbs\n\nA type representing a Gibbs sampler.\n\nConstructors\n\nGibbs needs to be given a set of pairs of variable names and samplers. Instead of a single variable name per sampler, one can also give an iterable of variables, all of which are sampled by the same component sampler.\n\nEach variable name can be given as either a Symbol or a VarName.\n\nSome examples of valid constructors are:\n\nGibbs(:x => NUTS(), :y => MH())\nGibbs(@varname(x) => NUTS(), @varname(y) => MH())\nGibbs((@varname(x), :y) => NUTS(), :z => MH())\n\nFields\n\nvarnames::NTuple{N, AbstractVector{<:AbstractPPL.VarName}} where N: varnames representing variables for each sampler\nsamplers::NTuple{N, Any} where N: samplers for each entry in varnames\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.GibbsConditional","page":"Inference","title":"Turing.Inference.GibbsConditional","text":"GibbsConditional(get_cond_dists)\n\nA Gibbs component sampler that samples variables according to user-provided analytical conditional posterior distributions.\n\nWhen using Gibbs sampling, sometimes one may know the analytical form of the posterior for a given variable, given the conditioned values of the other variables. In such cases one can use GibbsConditional as a component sampler to to sample from these known conditionals directly, avoiding any MCMC methods. One does so with\n\nsampler = Gibbs(\n    (@varname(var1), @varname(var2)) => GibbsConditional(get_cond_dists),\n    other samplers go here...\n)\n\nHere get_cond_dists(c::Dict{<:VarName}) should be a function that takes a Dict mapping the conditioned variables (anything other than var1 and var2) to their values, and returns the conditional posterior distributions for var1 and var2. You may, of course, have any number of variables being sampled as a block in this manner, we only use two as an example. The return value of get_cond_dists should be one of the following:\n\nA single Distribution, if only one variable is being sampled.\nAn AbstractDict{<:VarName,<:Distribution} that maps the variables being sampled to their conditional posteriors E.g. Dict(@varname(var1) => dist1, @varname(var2) => dist2).\nA NamedTuple of Distributions, which is like the AbstractDict case but can be used if all the variable names are single Symbols, and may be more performant. E.g. (; var1=dist1, var2=dist2).\n\nExamples\n\n# Define a model\n@model function inverse_gdemo(x)\n    precision ~ Gamma(2, inv(3))\n    std = sqrt(1 / precision)\n    m ~ Normal(0, std)\n    for i in eachindex(x)\n        x[i] ~ Normal(m, std)\n    end\nend\n\n# Define analytical conditionals. See\n# https://en.wikipedia.org/wiki/Conjugate_prior#When_likelihood_function_is_a_continuous_distribution\nfunction cond_precision(c)\n    a = 2.0\n    b = 3.0\n    # We use AbstractPPL.getvalue instead of indexing into `c` directly to guard against\n    # issues where e.g. you try to get `c[@varname(x[1])]` but only `@varname(x)` is present\n    # in `c`. `getvalue` handles that gracefully, `getindex` doesn't. In this case\n    # `getindex` would suffice, but `getvalue` is good practice.\n    m = AbstractPPL.getvalue(c, @varname(m))\n    x = AbstractPPL.getvalue(c, @varname(x))\n    n = length(x)\n    a_new = a + (n + 1) / 2\n    b_new = b + sum(abs2, x .- m) / 2 + m^2 / 2\n    return Gamma(a_new, 1 / b_new)\nend\n\nfunction cond_m(c)\n    precision = AbstractPPL.getvalue(c, @varname(precision))\n    x = AbstractPPL.getvalue(c, @varname(x))\n    n = length(x)\n    m_mean = sum(x) / (n + 1)\n    m_var = 1 / (precision * (n + 1))\n    return Normal(m_mean, sqrt(m_var))\nend\n\n# Sample using GibbsConditional\nmodel = inverse_gdemo([1.0, 2.0, 3.0])\nchain = sample(model, Gibbs(\n    :precision => GibbsConditional(cond_precision),\n    :m => GibbsConditional(cond_m)\n), 1000)\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.GibbsContext","page":"Inference","title":"Turing.Inference.GibbsContext","text":"GibbsContext(target_varnames, global_varinfo, context)\n\nA context used in the implementation of the Turing.jl Gibbs sampler.\n\nThere will be one GibbsContext for each iteration of a component sampler.\n\ntarget_varnames is a a tuple of VarNames that the current component sampler is sampling. For those VarNames, GibbsContext will just pass tilde_assume!! calls to its child context. For other variables, their values will be fixed to the values they have in global_varinfo.\n\nFields\n\ntarget_varnames: the VarNames being sampled\n\nglobal_varinfo: a Ref to the global AbstractVarInfo object that holds values for all variables, both those fixed and those being sampled. We use a Ref because this field may need to be updated if new variables are introduced.\n\ncontext: the child context that tilde calls will eventually be passed onto.\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.HMC","page":"Inference","title":"Turing.Inference.HMC","text":"HMC(ϵ::Float64, n_leapfrog::Int; adtype::ADTypes.AbstractADType = AutoForwardDiff())\n\nHamiltonian Monte Carlo sampler with static trajectory.\n\nArguments\n\nϵ: The leapfrog step size to use.\nn_leapfrog: The number of leapfrog steps to use.\nadtype: The automatic differentiation (AD) backend.   If not specified, ForwardDiff is used, with its chunksize automatically determined.\n\nUsage\n\nHMC(0.05, 10)\n\nTips\n\nIf you are receiving gradient errors when using HMC, try reducing the leapfrog step size ϵ, e.g.\n\n# Original step size\nsample(gdemo([1.5, 2]), HMC(0.1, 10), 1000)\n\n# Reduced step size\nsample(gdemo([1.5, 2]), HMC(0.01, 10), 1000)\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.HMCDA","page":"Inference","title":"Turing.Inference.HMCDA","text":"HMCDA(\n    n_adapts::Int, δ::Float64, λ::Float64; ϵ::Float64 = 0.0;\n    adtype::ADTypes.AbstractADType = AutoForwardDiff(),\n)\n\nHamiltonian Monte Carlo sampler with Dual Averaging algorithm.\n\nUsage\n\nHMCDA(200, 0.65, 0.3)\n\nArguments\n\nn_adapts: Numbers of samples to use for adaptation.\nδ: Target acceptance rate. 65% is often recommended.\nλ: Target leapfrog length.\nϵ: Initial step size; 0 means automatically search by Turing.\nadtype: The automatic differentiation (AD) backend.   If not specified, ForwardDiff is used, with its chunksize automatically determined.\n\nReference\n\nFor more information, please view the following paper (arXiv link):\n\nHoffman, Matthew D., and Andrew Gelman. \"The No-U-turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.\" Journal of Machine Learning Research 15, no. 1 (2014): 1593-1623.\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.IS","page":"Inference","title":"Turing.Inference.IS","text":"IS()\n\nImportance sampling algorithm.\n\nUsage:\n\nIS()\n\nExample:\n\n# Define a simple Normal model with unknown mean and variance.\n@model function gdemo(x)\n    s² ~ InverseGamma(2,3)\n    m ~ Normal(0,sqrt.(s))\n    x[1] ~ Normal(m, sqrt.(s))\n    x[2] ~ Normal(m, sqrt.(s))\n    return s², m\nend\n\nsample(gdemo([1.5, 2]), IS(), 1000)\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.MH","page":"Inference","title":"Turing.Inference.MH","text":"MH(proposals...)\n\nConstruct a Metropolis-Hastings algorithm.\n\nThe arguments proposals can be\n\nBlank (i.e. MH()), in which case MH defaults to using the prior for each parameter as the proposal distribution.\nAn iterable of pairs or tuples mapping a Symbol to a AdvancedMH.Proposal, Distribution, or Function that returns a conditional proposal distribution.\nA covariance matrix to use as for mean-zero multivariate normal proposals.\n\nExamples\n\nThe default MH will draw proposal samples from the prior distribution using AdvancedMH.StaticProposal.\n\n@model function gdemo(x, y)\n    s² ~ InverseGamma(2,3)\n    m ~ Normal(0, sqrt(s²))\n    x ~ Normal(m, sqrt(s²))\n    y ~ Normal(m, sqrt(s²))\nend\n\nchain = sample(gdemo(1.5, 2.0), MH(), 1_000)\nmean(chain)\n\nSpecifying a single distribution implies the use of static MH:\n\n# Use a static proposal for s² (which happens to be the same\n# as the prior) and a static proposal for m (note that this\n# isn't a random walk proposal).\nchain = sample(\n    gdemo(1.5, 2.0),\n    MH(\n        :s² => InverseGamma(2, 3),\n        :m => Normal(0, 1)\n    ),\n    1_000\n)\nmean(chain)\n\nSpecifying explicit proposals using the AdvancedMH interface:\n\n# Use a static proposal for s² and random walk with proposal\n# standard deviation of 0.25 for m.\nchain = sample(\n    gdemo(1.5, 2.0),\n    MH(\n        :s² => AdvancedMH.StaticProposal(InverseGamma(2,3)),\n        :m => AdvancedMH.RandomWalkProposal(Normal(0, 0.25))\n    ),\n    1_000\n)\nmean(chain)\n\nUsing a custom function to specify a conditional distribution:\n\n# Use a static proposal for s and and a conditional proposal for m,\n# where the proposal is centered around the current sample.\nchain = sample(\n    gdemo(1.5, 2.0),\n    MH(\n        :s² => InverseGamma(2, 3),\n        :m => x -> Normal(x, 1)\n    ),\n    1_000\n)\nmean(chain)\n\nProviding a covariance matrix will cause MH to perform random-walk sampling in the transformed space with proposals drawn from a multivariate normal distribution. The provided matrix must be positive semi-definite and square:\n\n# Providing a custom variance-covariance matrix\nchain = sample(\n    gdemo(1.5, 2.0),\n    MH(\n        [0.25 0.05;\n         0.05 0.50]\n    ),\n    1_000\n)\nmean(chain)\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.MHState","page":"Inference","title":"Turing.Inference.MHState","text":"MHState(varinfo::AbstractVarInfo, logjoint_internal::Real)\n\nState for Metropolis-Hastings sampling.\n\nvarinfo must have the correct parameters set inside it, but its other fields (e.g. accumulators, which track logp) can in general be missing or incorrect.\n\nlogjoint_internal is the log joint probability of the model, evaluated using the parameters and linking status of varinfo. It should be equal to DynamicPPL.getlogjoint_internal(varinfo). This information is returned by the MH sampler so we store this here to avoid re-evaluating the model unnecessarily.\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.NUTS","page":"Inference","title":"Turing.Inference.NUTS","text":"NUTS(n_adapts::Int, δ::Float64; max_depth::Int=10, Δ_max::Float64=1000.0, init_ϵ::Float64=0.0; adtype::ADTypes.AbstractADType=AutoForwardDiff()\n\nNo-U-Turn Sampler (NUTS) sampler.\n\nUsage:\n\nNUTS()            # Use default NUTS configuration.\nNUTS(1000, 0.65)  # Use 1000 adaption steps, and target accept ratio 0.65.\n\nArguments:\n\nn_adapts::Int : The number of samples to use with adaptation.\nδ::Float64 : Target acceptance rate for dual averaging.\nmax_depth::Int : Maximum doubling tree depth.\nΔ_max::Float64 : Maximum divergence during doubling tree.\ninit_ϵ::Float64 : Initial step size; 0 means automatically searching using a heuristic procedure.\nadtype::ADTypes.AbstractADType : The automatic differentiation (AD) backend.   If not specified, ForwardDiff is used, with its chunksize automatically determined.\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.OldLogDensityFunction","page":"Inference","title":"Turing.Inference.OldLogDensityFunction","text":"OldLogDensityFunction\n\nThis is a clone of pre-0.39 DynamicPPL.LogDensityFunction. It is needed for MH because MH doesn't actually obey the LogDensityProblems.jl interface: it evaluates 'LogDensityFunctions' with a NamedTuple(!!)\n\nThis means that we can't really use DynamicPPL's LogDensityFunction, since that only promises to obey the interface of being called with a vector.\n\nIn particular, because set_namedtuple! acts on a VarInfo, we need to store the VarInfo inside this struct (which DynamicPPL's LogDensityFunction no longer does).\n\nThis SHOULD really be refactored to remove this requirement.\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.PG","page":"Inference","title":"Turing.Inference.PG","text":"struct PG{R} <: Turing.Inference.ParticleInference\n\nParticle Gibbs sampler.\n\nFields\n\nnparticles::Int64: Number of particles.\nresampler::Any: Resampling algorithm.\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.PG-Tuple{Int64}","page":"Inference","title":"Turing.Inference.PG","text":"PG(n, [resampler = AdvancedPS.ResampleWithESSThreshold()]) PG(n, [resampler = AdvancedPS.resample_systematic, ]threshold)\n\nCreate a Particle Gibbs sampler of type PG with n particles.\n\nIf the algorithm for the resampling step is not specified explicitly, systematic resampling is performed if the estimated effective sample size per particle drops below 0.5.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.PolynomialStepsize-Union{Tuple{T}, Tuple{T, T, T}} where T<:Real","page":"Inference","title":"Turing.Inference.PolynomialStepsize","text":"PolynomialStepsize(a[, b=0, γ=0.55])\n\nCreate a polynomially decaying stepsize function.\n\nAt iteration t, the step size is\n\na (b + t)^-γ\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.Prior","page":"Inference","title":"Turing.Inference.Prior","text":"Prior()\n\nAlgorithm for sampling from the prior.\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.ProduceLogLikelihoodAccumulator","page":"Inference","title":"Turing.Inference.ProduceLogLikelihoodAccumulator","text":"ProduceLogLikelihoodAccumulator{T<:Real} <: AbstractAccumulator\n\nExactly like LogLikelihoodAccumulator, but calls Libtask.produce on change of value.\n\nFields\n\nlogp::Real: the scalar log likelihood value\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.RepeatSampler","page":"Inference","title":"Turing.Inference.RepeatSampler","text":"RepeatSampler <: AbstractMCMC.AbstractSampler\n\nA RepeatSampler is a container for a sampler and a number of times to repeat it.\n\nFields\n\nsampler: The sampler to repeat\nnum_repeat: The number of times to repeat the sampler\n\nExamples\n\nrepeated_sampler = RepeatSampler(sampler, 10)\nAbstractMCMC.step(rng, model, repeated_sampler) # take 10 steps of `sampler`\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.SGHMC","page":"Inference","title":"Turing.Inference.SGHMC","text":"SGHMC{AD}\n\nStochastic Gradient Hamiltonian Monte Carlo (SGHMC) sampler.\n\nFields\n\nlearning_rate::Real\nmomentum_decay::Real\nadtype::Any\n\nReference\n\nTianqi Chen, Emily Fox, & Carlos Guestrin (2014). Stochastic Gradient Hamiltonian Monte Carlo. In: Proceedings of the 31st International Conference on Machine Learning (pp. 1683–1691).\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.SGHMC-Tuple{}","page":"Inference","title":"Turing.Inference.SGHMC","text":"SGHMC(;\n    learning_rate::Real,\n    momentum_decay::Real,\n    adtype::ADTypes.AbstractADType = AutoForwardDiff(),\n)\n\nCreate a Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) sampler.\n\nIf the automatic differentiation (AD) backend adtype is not provided, ForwardDiff with automatically determined chunksize is used.\n\nReference\n\nTianqi Chen, Emily Fox, & Carlos Guestrin (2014). Stochastic Gradient Hamiltonian Monte Carlo. In: Proceedings of the 31st International Conference on Machine Learning (pp. 1683–1691).\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.SGLD","page":"Inference","title":"Turing.Inference.SGLD","text":"SGLD\n\nStochastic gradient Langevin dynamics (SGLD) sampler.\n\nFields\n\nstepsize::Any: Step size function.\nadtype::Any\n\nReference\n\nMax Welling & Yee Whye Teh (2011). Bayesian Learning via Stochastic Gradient Langevin Dynamics. In: Proceedings of the 28th International Conference on Machine Learning (pp. 681–688).\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.SGLD-Tuple{}","page":"Inference","title":"Turing.Inference.SGLD","text":"SGLD(;\n    stepsize = PolynomialStepsize(0.01),\n    adtype::ADTypes.AbstractADType = AutoForwardDiff(),\n)\n\nStochastic gradient Langevin dynamics (SGLD) sampler.\n\nBy default, a polynomially decaying stepsize is used.\n\nIf the automatic differentiation (AD) backend adtype is not provided, ForwardDiff with automatically determined chunksize is used.\n\nReference\n\nMax Welling & Yee Whye Teh (2011). Bayesian Learning via Stochastic Gradient Langevin Dynamics. In: Proceedings of the 28th International Conference on Machine Learning (pp. 681–688).\n\nSee also: PolynomialStepsize\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.SMC","page":"Inference","title":"Turing.Inference.SMC","text":"struct SMC{R} <: Turing.Inference.ParticleInference\n\nSequential Monte Carlo sampler.\n\nFields\n\nresampler::Any\n\n\n\n\n\n","category":"type"},{"location":"api/Inference/#Turing.Inference.SMC-Tuple{}","page":"Inference","title":"Turing.Inference.SMC","text":"SMC([resampler = AdvancedPS.ResampleWithESSThreshold()]) SMC([resampler = AdvancedPS.resample_systematic, ]threshold)\n\nCreate a sequential Monte Carlo sampler of type SMC.\n\nIf the algorithm for the resampling step is not specified explicitly, systematic resampling is performed if the estimated effective sample size per particle drops below 0.5.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.build_variable_dict-Tuple{DynamicPPL.Model}","page":"Inference","title":"Turing.Inference.build_variable_dict","text":"build_variable_dict(model::DynamicPPL.Model)\n\nTraverse the context stack of model and build a Dict of all the variable values that are set in GibbsContext, ConditionContext, or FixedContext.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.default_varinfo-Tuple{Random.AbstractRNG, DynamicPPL.Model, AbstractMCMC.AbstractSampler}","page":"Inference","title":"Turing.Inference.default_varinfo","text":"default_varinfo(rng, model, sampler)\n\nReturn a default varinfo object for the given model and sampler. The default method for this returns a NTVarInfo (i.e. 'typed varinfo').\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.dist_val_tuple-Tuple{MH, Union{DynamicPPL.ThreadSafeVarInfo{<:DynamicPPL.VarInfo{Tmeta}}, DynamicPPL.VarInfo{Tmeta}} where Tmeta}","page":"Inference","title":"Turing.Inference.dist_val_tuple","text":"dist_val_tuple(spl::MH, vi::VarInfo)\n\nReturn two NamedTuples.\n\nThe first NamedTuple has symbols as keys and distributions as values. The second NamedTuple has model symbols as keys and their stored values as values.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.externalsampler-Tuple{AbstractMCMC.AbstractSampler}","page":"Inference","title":"Turing.Inference.externalsampler","text":"externalsampler(\n    sampler::AbstractSampler;\n    adtype=AutoForwardDiff(),\n    unconstrained=AbstractMCMC.requires_unconstrained_space(sampler),\n)\n\nWrap a sampler so it can be used as an inference algorithm.\n\nArguments\n\nsampler::AbstractSampler: The sampler to wrap.\n\nKeyword Arguments\n\nadtype::ADTypes.AbstractADType=ADTypes.AutoForwardDiff(): The automatic differentiation (AD) backend to use.\nunconstrained::Bool=AbstractMCMC.requires_unconstrained_space(sampler): Whether the sampler requires unconstrained space.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.get_trace_local_resampled_maybe-Tuple{Bool}","page":"Inference","title":"Turing.Inference.get_trace_local_resampled_maybe","text":"gettracelocalresampledmaybe(fallback_resampled::Bool)\n\nGet the Trace local resampled if one exists.\n\nIf executed within a TapedTask, return the resampled stored in the \"taped globals\" of the task, otherwise return fallback_resampled.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.get_trace_local_rng_maybe-Tuple{Random.AbstractRNG}","page":"Inference","title":"Turing.Inference.get_trace_local_rng_maybe","text":"gettracelocalrngmaybe(rng::Random.AbstractRNG)\n\nGet the Trace local rng if one exists.\n\nIf executed within a TapedTask, return the rng stored in the \"taped globals\" of the task, otherwise return vi.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.get_trace_local_varinfo_maybe-Tuple{DynamicPPL.AbstractVarInfo}","page":"Inference","title":"Turing.Inference.get_trace_local_varinfo_maybe","text":"gettracelocalvarinfomaybe(vi::AbstractVarInfo)\n\nGet the Trace local varinfo if one exists.\n\nIf executed within a TapedTask, return the varinfo stored in the \"taped globals\" of the task, otherwise return vi.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.gibbs_initialstep_recursive","page":"Inference","title":"Turing.Inference.gibbs_initialstep_recursive","text":"Take the first step of MCMC for the first component sampler, and call the same function recursively on the remaining samplers, until no samplers remain. Return the global VarInfo and a tuple of initial states for all component samplers.\n\nThe step_function argument should always be either AbstractMCMC.step or AbstractMCMC.step_warmup.\n\n\n\n\n\n","category":"function"},{"location":"api/Inference/#Turing.Inference.gibbs_step_recursive","page":"Inference","title":"Turing.Inference.gibbs_step_recursive","text":"Run a Gibbs step for the first varname/sampler/state tuple, and recursively call the same function on the tail, until there are no more samplers left.\n\nThe step_function argument should always be either AbstractMCMC.step or AbstractMCMC.step_warmup.\n\n\n\n\n\n","category":"function"},{"location":"api/Inference/#Turing.Inference.init_strategy-Tuple{AbstractMCMC.AbstractSampler}","page":"Inference","title":"Turing.Inference.init_strategy","text":"Turing.Inference.init_strategy(spl::AbstractSampler)\n\nGet the default initialization strategy for a given sampler spl, i.e. how initial parameters for sampling are chosen if not specified by the user. By default, this is InitFromPrior(), which samples initial parameters from the prior distribution.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.initial_varinfo-Tuple{Any, Any, Any, DynamicPPL.AbstractInitStrategy}","page":"Inference","title":"Turing.Inference.initial_varinfo","text":"Initialise a VarInfo for the Gibbs sampler.\n\nThis is straight up copypasta from DynamicPPL's src/sampler.jl. It is repeated here to support calling both step and stepwarmup as the initial step. DynamicPPL initialstep is incompatible with stepwarmup.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.isgibbscomponent-Tuple{AbstractMCMC.AbstractSampler}","page":"Inference","title":"Turing.Inference.isgibbscomponent","text":"isgibbscomponent(spl::AbstractSampler)\n\nReturn a boolean indicating whether spl is a valid component for a Gibbs sampler.\n\nDefaults to true if no method has been defined for a particular sampler.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.loadstate-Tuple{Chains}","page":"Inference","title":"Turing.Inference.loadstate","text":"loadstate(chain::MCMCChains.Chains)\n\nLoad the final state of the sampler from a MCMCChains.Chains object.\n\nTo save the final state of the sampler, you must use sample(...; save_state=true). If this argument was not used during sampling, calling loadstate will throw an error.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.make_conditional-Tuple{DynamicPPL.Model, AbstractVector{<:AbstractPPL.VarName}, Any}","page":"Inference","title":"Turing.Inference.make_conditional","text":"make_conditional(model, target_variables, varinfo)\n\nReturn a new, conditioned model for a component of a Gibbs sampler.\n\nArguments\n\nmodel::DynamicPPL.Model: The model to condition.\ntarget_variables::AbstractVector{<:VarName}: The target variables of the component\n\nsampler. These will not be conditioned.\n\nvarinfo::DynamicPPL.AbstractVarInfo: Values for all variables in the model. All the\n\nvalues in varinfo but not in target_variables will be conditioned to the values they have in varinfo.\n\nReturns\n\nA new model with the variables not in target_variables conditioned.\nThe GibbsContext object that will be used to condition the variables. This is necessary\n\nbecause evaluation can mutate its global_varinfo field, which we need to access later.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.match_linking!!-Tuple{Any, Any, Any}","page":"Inference","title":"Turing.Inference.match_linking!!","text":"match_linking!!(varinfo_local, prev_state_local, model)\n\nMake sure the linked/invlinked status of varinfo_local matches that of the previous state for this sampler. This is relevant when multiple samplers are sampling the same variables, and one might need it to be linked while the other doesn't.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.mh_accept-Tuple{Real, Real, Real}","page":"Inference","title":"Turing.Inference.mh_accept","text":"mh_accept(logp_current::Real, logp_proposal::Real, log_proposal_ratio::Real)\n\nDecide if a proposal x with log probability log p(x) = logp_proposal and log proposal ratio log k(x x) - log k(x x) = log_proposal_ratio in a Metropolis-Hastings algorithm with Markov kernel k(x_t x_t+1) and current state x with log probability log p(x) = logp_current is accepted by evaluating the Metropolis-Hastings acceptance criterion\n\nlog U leq log p(x) - log p(x) + log k(x x) - log k(x x)\n\nfor a uniform random number U in 0 1).\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.set_namedtuple!-Tuple{Union{DynamicPPL.ThreadSafeVarInfo{<:DynamicPPL.VarInfo{Tmeta}}, DynamicPPL.VarInfo{Tmeta}} where Tmeta, NamedTuple}","page":"Inference","title":"Turing.Inference.set_namedtuple!","text":"set_namedtuple!(vi::VarInfo, nt::NamedTuple)\n\nPlaces the values of a NamedTuple into the relevant places of a VarInfo.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.set_trace_local_varinfo_maybe-Tuple{DynamicPPL.AbstractVarInfo}","page":"Inference","title":"Turing.Inference.set_trace_local_varinfo_maybe","text":"settracelocalvarinfomaybe(vi::AbstractVarInfo)\n\nSet the Trace local varinfo if executing within a Trace. Return nothing.\n\nIf executed within a TapedTask, set the varinfo stored in the \"taped globals\" of the task. Otherwise do nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/Inference/#Turing.Inference.setparams_varinfo!!-Tuple{DynamicPPL.Model, AbstractMCMC.AbstractSampler, Any, DynamicPPL.AbstractVarInfo}","page":"Inference","title":"Turing.Inference.setparams_varinfo!!","text":"setparams_varinfo!!(model::DynamicPPL.Model, sampler::AbstractSampler, state, params::AbstractVarInfo)\n\nA lot like AbstractMCMC.setparams!!, but instead of taking a vector of parameters, takes an AbstractVarInfo object. Also takes the sampler as an argument. By default, falls back to AbstractMCMC.setparams!!(model, state, params[:]).\n\n\n\n\n\n","category":"method"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#Module-wide-re-exports","page":"API","title":"Module-wide re-exports","text":"Turing.jl directly re-exports the entire public API of the following packages:\n\nDistributions.jl\nMCMCChains.jl\n\nPlease see the individual packages for their documentation.","category":"section"},{"location":"api/#Individual-exports-and-re-exports","page":"API","title":"Individual exports and re-exports","text":"In this API documentation, for the sake of clarity, we have listed the module that actually defines each of the exported symbols. Note, however, that all of the following symbols are exported unqualified by Turing. That means, for example, you can just write\n\nusing Turing\n\n@model function my_model() end\n\nsample(my_model(), Prior(), 100)\n\ninstead of\n\nDynamicPPL.@model function my_model() end\n\nsample(my_model(), Turing.Inference.Prior(), 100)\n\neven though Prior() is actually defined in the Turing.Inference module and @model in the DynamicPPL package.","category":"section"},{"location":"api/#Modelling","page":"API","title":"Modelling","text":"Exported symbol Documentation Description\n@model DynamicPPL.@model Define a probabilistic model\n@varname AbstractPPL.@varname Generate a VarName from a Julia expression\nto_submodel DynamicPPL.to_submodel Define a submodel\nprefix DynamicPPL.prefix Prefix all variable names in a model with a given VarName\nLogDensityFunction DynamicPPL.LogDensityFunction A struct containing all information about how to evaluate a model. Mostly for advanced users\n@addlogprob! DynamicPPL.@addlogprob! Add arbitrary log-probability terms during model evaluation\nsetthreadsafe DynamicPPL.setthreadsafe Mark a model as requiring threadsafe evaluation","category":"section"},{"location":"api/#Inference","page":"API","title":"Inference","text":"Exported symbol Documentation Description\nsample StatsBase.sample Sample from a model\nMCMCThreads AbstractMCMC.MCMCThreads Run MCMC using multiple threads\nMCMCDistributed AbstractMCMC.MCMCDistributed Run MCMC using multiple processes\nMCMCSerial AbstractMCMC.MCMCSerial Run MCMC using without parallelism\nloadstate Turing.Inference.loadstate Load saved state from MCMCChains.Chains","category":"section"},{"location":"api/#Samplers","page":"API","title":"Samplers","text":"Exported symbol Documentation Description\nPrior Turing.Inference.Prior Sample from the prior distribution\nMH Turing.Inference.MH Metropolis–Hastings\nEmcee Turing.Inference.Emcee Affine-invariant ensemble sampler\nESS Turing.Inference.ESS Elliptical slice sampling\nGibbs Turing.Inference.Gibbs Gibbs sampling\nGibbsConditional Turing.Inference.GibbsConditional Gibbs sampling with analytical conditional posterior distributions\nHMC Turing.Inference.HMC Hamiltonian Monte Carlo\nSGLD Turing.Inference.SGLD Stochastic gradient Langevin dynamics\nSGHMC Turing.Inference.SGHMC Stochastic gradient Hamiltonian Monte Carlo\nPolynomialStepsize Turing.Inference.PolynomialStepsize Returns a function which generates polynomially decaying step sizes\nHMCDA Turing.Inference.HMCDA Hamiltonian Monte Carlo with dual averaging\nNUTS Turing.Inference.NUTS No-U-Turn Sampler\nIS Turing.Inference.IS Importance sampling\nSMC Turing.Inference.SMC Sequential Monte Carlo\nPG Turing.Inference.PG Particle Gibbs\nCSMC Turing.Inference.CSMC The same as PG\nRepeatSampler Turing.Inference.RepeatSampler A sampler that runs multiple times on the same variable\nexternalsampler Turing.Inference.externalsampler Wrap an external sampler for use in Turing","category":"section"},{"location":"api/#DynamicPPL-utilities","page":"API","title":"DynamicPPL utilities","text":"Please see the generated quantities and probability interface guides for more information.\n\nExported symbol Documentation Description\nreturned DynamicPPL.returned Calculate additional quantities defined in a model\npredict StatsAPI.predict Generate samples from posterior predictive distribution\npointwise_loglikelihoods DynamicPPL.pointwise_loglikelihoods Compute log likelihoods for each sample in a chain\nlogprior DynamicPPL.logprior Compute log prior probability\nlogjoint DynamicPPL.logjoint Compute log joint probability\ncondition AbstractPPL.condition Condition a model on data\ndecondition AbstractPPL.decondition Remove conditioning on data\nconditioned DynamicPPL.conditioned Return the conditioned values of a model\nfix DynamicPPL.fix Fix the value of a variable\nunfix DynamicPPL.unfix Unfix the value of a variable\nOrderedDict OrderedCollections.OrderedDict An ordered dictionary","category":"section"},{"location":"api/#Initialisation-strategies","page":"API","title":"Initialisation strategies","text":"Turing.jl provides several strategies to initialise parameters for models.\n\nExported symbol Documentation Description\nInitFromPrior DynamicPPL.InitFromPrior Obtain initial parameters from the prior distribution\nInitFromUniform DynamicPPL.InitFromUniform Obtain initial parameters by sampling uniformly in linked space\nInitFromParams DynamicPPL.InitFromParams Manually specify (possibly a subset of) initial parameters","category":"section"},{"location":"api/#Variational-inference","page":"API","title":"Variational inference","text":"See the docs of AdvancedVI.jl for detailed usage and the variational inference tutorial for a basic walkthrough.\n\nExported symbol Documentation Description\nvi Turing.vi Perform variational inference\nq_locationscale Turing.Variational.q_locationscale Find a numerically non-degenerate initialization for a location-scale variational family\nq_meanfield_gaussian Turing.Variational.q_meanfield_gaussian Find a numerically non-degenerate initialization for a mean-field Gaussian family\nq_fullrank_gaussian Turing.Variational.q_fullrank_gaussian Find a numerically non-degenerate initialization for a full-rank Gaussian family\nKLMinRepGradDescent Turing.Variational.KLMinRepGradDescent KL divergence minimization via stochastic gradient descent with the reparameterization gradient\nKLMinRepGradProxDescent Turing.Variational.KLMinRepGradProxDescent KL divergence minimization via stochastic proximal gradient descent with the reparameterization gradient over location-scale variational families\nKLMinScoreGradDescent Turing.Variational.KLMinScoreGradDescent KL divergence minimization via stochastic gradient descent with the score gradient\nKLMinWassFwdBwd Turing.Variational.KLMinWassFwdBwd KL divergence minimization via Wasserstein proximal gradient descent\nKLMinNaturalGradDescent Turing.Variational.KLMinNaturalGradDescent KL divergence minimization via natural gradient descent\nKLMinSqrtNaturalGradDescent Turing.Variational.KLMinSqrtNaturalGradDescent KL divergence minimization via natural gradient descent in the square-root parameterization\nFisherMinBatchMatch Turing.Variational.FisherMinBatchMatch Covariance-weighted Fisher divergence minimization via the batch-and-match algorithm","category":"section"},{"location":"api/#Automatic-differentiation-types","page":"API","title":"Automatic differentiation types","text":"These are used to specify the automatic differentiation backend to use. See the AD guide for more information.\n\nExported symbol Documentation Description\nAutoEnzyme ADTypes.AutoEnzyme Enzyme.jl backend\nAutoForwardDiff ADTypes.AutoForwardDiff ForwardDiff.jl backend\nAutoMooncake ADTypes.AutoMooncake Mooncake.jl backend\nAutoReverseDiff ADTypes.AutoReverseDiff ReverseDiff.jl backend","category":"section"},{"location":"api/#Debugging","page":"API","title":"Debugging","text":"","category":"section"},{"location":"api/#Distributions","page":"API","title":"Distributions","text":"These distributions are defined in Turing.jl, but not in Distributions.jl.","category":"section"},{"location":"api/#Tools-to-work-with-distributions","page":"API","title":"Tools to work with distributions","text":"Exported symbol Documentation Description\nI LinearAlgebra.I Identity matrix\nfilldist DistributionsAD.filldist Create a product distribution from a distribution and integers\narraydist DistributionsAD.arraydist Create a product distribution from an array of distributions\nNamedDist DynamicPPL.NamedDist A distribution that carries the name of the variable","category":"section"},{"location":"api/#Point-estimates","page":"API","title":"Point estimates","text":"See the mode estimation tutorial for more information.\n\nExported symbol Documentation Description\nmaximum_a_posteriori Turing.Optimisation.maximum_a_posteriori Find a MAP estimate for a model\nmaximum_likelihood Turing.Optimisation.maximum_likelihood Find a MLE estimate for a model\nMAP Turing.Optimisation.MAP Type to use with Optim.jl for MAP estimation\nMLE Turing.Optimisation.MLE Type to use with Optim.jl for MLE estimation","category":"section"},{"location":"api/#Turing.setprogress!","page":"API","title":"Turing.setprogress!","text":"setprogress!(progress::Bool)\n\nEnable progress logging in Turing if progress is true, and disable it otherwise.\n\n\n\n\n\n","category":"function"},{"location":"api/#Turing.Flat","page":"API","title":"Turing.Flat","text":"Flat()\n\nThe flat distribution is the improper distribution of real numbers that has the improper probability density function\n\nf(x) = 1\n\n\n\n\n\n","category":"type"},{"location":"api/#Turing.FlatPos","page":"API","title":"Turing.FlatPos","text":"FlatPos(l::Real)\n\nThe positive flat distribution with real-valued parameter l is the improper distribution of real numbers that has the improper probability density function\n\nf(x) = begincases\n0  textif  x leq l \n1  textotherwise\nendcases\n\n\n\n\n\n","category":"type"},{"location":"api/#Turing.BinomialLogit","page":"API","title":"Turing.BinomialLogit","text":"BinomialLogit(n, logitp)\n\nThe Binomial distribution with logit parameterization characterizes the number of successes in a sequence of independent trials.\n\nIt has two parameters: n, the number of trials, and logitp, the logit of the probability of success in an individual trial, with the distribution\n\nP(X = k) = n choose k(textlogistic(logitp))^k (1 - textlogistic(logitp))^n-k quad text for  k = 012 ldots n\n\nSee also: Distributions.Binomial\n\n\n\n\n\n","category":"type"},{"location":"api/#Turing.OrderedLogistic","page":"API","title":"Turing.OrderedLogistic","text":"OrderedLogistic(η, c::AbstractVector)\n\nThe ordered logistic distribution with real-valued parameter η and cutpoints c has the probability mass function\n\nP(X = k) = begincases\n    1 - textlogistic(eta - c_1)  textif  k = 1 \n    textlogistic(eta - c_k-1) - textlogistic(eta - c_k)  textif  1  k  K \n    textlogistic(eta - c_K-1)  textif  k = K\nendcases\n\nwhere K = length(c) + 1.\n\n\n\n\n\n","category":"type"},{"location":"api/#Turing.LogPoisson","page":"API","title":"Turing.LogPoisson","text":"LogPoisson(logλ)\n\nThe Poisson distribution with logarithmic parameterization of the rate parameter describes the number of independent events occurring within a unit time interval, given the average rate of occurrence exp(loglambda).\n\nThe distribution has the probability mass function\n\nP(X = k) = frace^k cdot loglambdak e^-e^loglambda quad text for  k = 012ldots\n\nSee also: Distributions.Poisson\n\n\n\n\n\n","category":"type"},{"location":"api/RandomMeasures/#API:-Turing.RandomMeasures","page":"RandomMeasures ","title":"API: Turing.RandomMeasures","text":"","category":"section"},{"location":"api/RandomMeasures/#Turing.RandomMeasures.ChineseRestaurantProcess","page":"RandomMeasures ","title":"Turing.RandomMeasures.ChineseRestaurantProcess","text":"ChineseRestaurantProcess(rpm, m)\n\nThe Chinese Restaurant Process for random probability measures rpm with counts m.\n\n\n\n\n\n","category":"type"},{"location":"api/RandomMeasures/#Turing.RandomMeasures.DirichletProcess","page":"RandomMeasures ","title":"Turing.RandomMeasures.DirichletProcess","text":"DirichletProcess(α)\n\nThe Dirichlet Process with concentration parameter α. Samples from the Dirichlet process can be constructed via the following representations.\n\nSize-Biased Sampling Process\n\nj_k sim Beta(1 alpha) * surplus\n\nStick-Breaking Process\n\nv_k sim Beta(1 alpha)\n\nChinese Restaurant Process\n\np(z_n = k  z_1n-1) propto begincases\n        fracm_kn-1+alpha textif m_k  0\n        fracalphan-1+alpha\n    endcases\n\nFor more details see: https://www.stats.ox.ac.uk/~teh/research/npbayes/Teh2010a.pdf\n\n\n\n\n\n","category":"type"},{"location":"api/RandomMeasures/#Turing.RandomMeasures.PitmanYorProcess","page":"RandomMeasures ","title":"Turing.RandomMeasures.PitmanYorProcess","text":"PitmanYorProcess(d, θ, t)\n\nThe Pitman-Yor Process with discount d, concentration θ and t already drawn atoms. Samples from the Pitman-Yor Process can be constructed via the following representations.\n\nSize-Biased Sampling Process\n\nj_k sim Beta(1-d theta + t*d) * surplus\n\nStick-Breaking Process\n\nv_k sim Beta(1-d theta + t*d)\n\nChinese Restaurant Process\n\np(z_n = k  z_1n-1) propto begincases\n        fracm_k - dn+theta textif m_k  0\n        fractheta + d*tn+theta\n    endcases\n\nFor more details see: https://en.wikipedia.org/wiki/Pitman–Yor_process\n\n\n\n\n\n","category":"type"},{"location":"api/RandomMeasures/#Turing.RandomMeasures.SizeBiasedSamplingProcess","page":"RandomMeasures ","title":"Turing.RandomMeasures.SizeBiasedSamplingProcess","text":"SizeBiasedSamplingProcess(rpm, surplus)\n\nThe Size-Biased Sampling Process for random probability measures rpm with a surplus mass of surplus.\n\n\n\n\n\n","category":"type"},{"location":"api/RandomMeasures/#Turing.RandomMeasures.StickBreakingProcess","page":"RandomMeasures ","title":"Turing.RandomMeasures.StickBreakingProcess","text":"StickBreakingProcess(rpm)\n\nThe Stick-Breaking Process for random probability measures rpm.\n\n\n\n\n\n","category":"type"},{"location":"api/RandomMeasures/#Turing.RandomMeasures._logpdf_table","page":"RandomMeasures ","title":"Turing.RandomMeasures._logpdf_table","text":"_logpdf_table(d::AbstractRandomProbabilityMeasure, m::AbstractVector{Int})\n\nParameters:\n\nd: Random probability measure, e.g. DirichletProcess\nm: Cluster counts\n\n\n\n\n\n","category":"function"},{"location":"api/RandomMeasures/#Turing.RandomMeasures.stickbreak-Tuple{Any}","page":"RandomMeasures ","title":"Turing.RandomMeasures.stickbreak","text":"Stick-breaking function.\n\nThis function accepts a vector (`v`) of length $K - 1$ where each element\nis assumed to be in the unit interval, and returns a simplex of length\n$K$.  If the supplied vector `v` is a vector of independent draws from\na Beta distribution (i.e., vⱼ | a ~ Beta(1, a), for j=1,...,K), then\nreturned simplex is generated via a stick-breaking process where\nthe first element of the stick is w₁ = v₁, the last element w_K =\n∏ⱼ (1 - vⱼ), and the other elements are wₖ = vₖ ∏ⱼ₌₁ᵏ⁻¹(1 - vⱼ).\nAs $K$ goes to infinity, w is a draw from the Chinese Restaurant process\nwith mass parameter a.\n\nArguments\n\nv: A vector of length K - 1, where K  1.\n\nReturn\n\nA simplex (w) of dimension K. Where ∑ₖ wₖ = 1, and each wₖ ≥ 0.\n\n\n\n\n\n","category":"method"},{"location":"#Turing.jl","page":"Home","title":"Turing.jl","text":"This site contains the API documentation for the identifiers exported by Turing.jl.\n\nIf you are looking for usage examples and guides, please visit https://turinglang.org/docs.","category":"section"},{"location":"api/Variational/#API:-Turing.Variational","page":"Variational ","title":"API: Turing.Variational","text":"","category":"section"},{"location":"api/Variational/#Turing.Variational.q_fullrank_gaussian-Tuple{Random.AbstractRNG, DynamicPPL.Model}","page":"Variational ","title":"Turing.Variational.q_fullrank_gaussian","text":"q_fullrank_gaussian(\n    [rng::Random.AbstractRNG,]\n    model::DynamicPPL.Model;\n    location::Union{Nothing,<:AbstractVector} = nothing,\n    scale::Union{Nothing,<:LowerTriangular} = nothing,\n    kwargs...\n)\n\nFind a numerically non-degenerate Gaussian q with a scale with full-rank factors (traditionally referred to as a \"full-rank family\") for approximating the target model.\n\nIf the scale set as nothing, the default value will be a zero-mean Gaussian with a LowerTriangular scale matrix (resulting in a covariance with \"full-rank\" factors) no larger than 0.6*I (covariance of 0.6^2*I). This guarantees that the samples from the initial variational approximation will fall in the range of (-2, 2) with 99.9% probability, which mimics the behavior of the Turing.InitFromUniform() strategy. Whether the default choice is used or not, the scale may be adjusted via q_initialize_scale so that the log-densities of model are finite over the samples from q.\n\nArguments\n\nmodel: The target DynamicPPL.Model.\n\nKeyword Arguments\n\nlocation: The location parameter of the initialization. If nothing, a vector of zeros is used.\nscale: The scale parameter of the initialization. If nothing, an identity matrix is used.\n\nThe remaining keyword arguments are passed to q_locationscale.\n\nReturns\n\nq::Bijectors.TransformedDistribution: A AdvancedVI.LocationScale distribution matching the support of model.\n\n\n\n\n\n","category":"method"},{"location":"api/Variational/#Turing.Variational.q_initialize_scale-Tuple{Random.AbstractRNG, DynamicPPL.Model, AbstractVector, AbstractMatrix, UnivariateDistribution}","page":"Variational ","title":"Turing.Variational.q_initialize_scale","text":"q_initialize_scale(\n    [rng::Random.AbstractRNG,]\n    model::DynamicPPL.Model,\n    location::AbstractVector,\n    scale::AbstractMatrix,\n    basedist::Distributions.UnivariateDistribution;\n    num_samples::Int = 10,\n    num_max_trials::Int = 10,\n    reduce_factor::Real = one(eltype(scale)) / 2\n)\n\nGiven an initial location-scale distribution q formed by location, scale, and basedist, shrink scale until the expectation of log-densities of model taken over q are finite. If the log-densities are not finite even after num_max_trials, throw an error.\n\nFor reference, a location-scale distribution q formed by location, scale, and basedist is a distribution where its sampling process z sim q can be represented as\n\nu = rand(basedist, d)\nz = scale * u + location\n\nArguments\n\nmodel: The target DynamicPPL.Model.\nlocation: The location parameter of the initialization.\nscale: The scale parameter of the initialization.\nbasedist: The base distribution of the location-scale family.\n\nKeyword Arguments\n\nnum_samples: Number of samples used to compute the average log-density at each trial.\nnum_max_trials: Number of trials until throwing an error.\nreduce_factor: Factor for shrinking the scale. After n trials, the scale is then scale*reduce_factor^n.\n\nReturns\n\nscale_adj: The adjusted scale matrix matching the type of scale.\n\n\n\n\n\n","category":"method"},{"location":"api/Variational/#Turing.Variational.q_locationscale-Tuple{Random.AbstractRNG, DynamicPPL.Model}","page":"Variational ","title":"Turing.Variational.q_locationscale","text":"q_locationscale(\n    [rng::Random.AbstractRNG,]\n    model::DynamicPPL.Model;\n    location::Union{Nothing,<:AbstractVector} = nothing,\n    scale::Union{Nothing,<:Diagonal,<:LowerTriangular} = nothing,\n    meanfield::Bool = true,\n    basedist::Distributions.UnivariateDistribution = Normal()\n)\n\nFind a numerically non-degenerate variational distribution q for approximating the  target model within the location-scale variational family formed by the type of scale and basedist.\n\nThe distribution can be manually specified by setting location, scale, and basedist. Otherwise, it chooses a Gaussian with zero-mean and scale 0.6*I (covariance of 0.6^2*I) by default. This guarantees that the samples from the initial variational approximation will fall in the range of (-2, 2) with 99.9% probability, which mimics the behavior of the Turing.InitFromUniform() strategy.\n\nWhether the default choice is used or not, the scale may be adjusted via q_initialize_scale so that the log-densities of model are finite over the samples from q. If meanfield is set as true, the scale of q is restricted to be a diagonal matrix and only the diagonal of scale is used.\n\nFor reference, a location-scale distribution q formed by location, scale, and basedist is a distribution where its sampling process z sim q can be represented as\n\nu = rand(basedist, d)\nz = scale * u + location\n\nArguments\n\nmodel: The target DynamicPPL.Model.\n\nKeyword Arguments\n\nlocation: The location parameter of the initialization. If nothing, a vector of zeros is used.\nscale: The scale parameter of the initialization. If nothing, an identity matrix is used.\nmeanfield: Whether to use the mean-field approximation. If true, scale is converted into a Diagonal matrix. Otherwise, it is converted into a LowerTriangular matrix.\nbasedist: The base distribution of the location-scale family.\n\nThe remaining keywords are passed to q_initialize_scale.\n\nReturns\n\nq::Bijectors.TransformedDistribution: A AdvancedVI.LocationScale distribution matching the support of model.\n\n\n\n\n\n","category":"method"},{"location":"api/Variational/#Turing.Variational.q_meanfield_gaussian-Tuple{Random.AbstractRNG, DynamicPPL.Model}","page":"Variational ","title":"Turing.Variational.q_meanfield_gaussian","text":"q_meanfield_gaussian(\n    [rng::Random.AbstractRNG,]\n    model::DynamicPPL.Model;\n    location::Union{Nothing,<:AbstractVector} = nothing,\n    scale::Union{Nothing,<:Diagonal} = nothing,\n    kwargs...\n)\n\nFind a numerically non-degenerate mean-field Gaussian q for approximating the  target model.\n\nIf the scale set as nothing, the default value will be a zero-mean Gaussian with a Diagonal scale matrix (the \"mean-field\" approximation) no larger than 0.6*I (covariance of 0.6^2*I). This guarantees that the samples from the initial variational approximation will fall in the range of (-2, 2) with 99.9% probability, which mimics the behavior of the Turing.InitFromUniform() strategy. Whether the default choice is used or not, the scale may be adjusted via q_initialize_scale so that the log-densities of model are finite over the samples from q.\n\nArguments\n\nmodel: The target DynamicPPL.Model.\n\nKeyword Arguments\n\nlocation: The location parameter of the initialization. If nothing, a vector of zeros is used.\nscale: The scale parameter of the initialization. If nothing, an identity matrix is used.\n\nThe remaining keyword arguments are passed to q_locationscale.\n\nReturns\n\nq::Bijectors.TransformedDistribution: A AdvancedVI.LocationScale distribution matching the support of model.\n\n\n\n\n\n","category":"method"},{"location":"api/Variational/#Turing.Variational.vi-Tuple{Random.AbstractRNG, DynamicPPL.Model, Any, Int64, Vararg{Any}}","page":"Variational ","title":"Turing.Variational.vi","text":"vi(\n    [rng::Random.AbstractRNG,]\n    model::DynamicPPL.Model,\n    q,\n    max_iter::Int;\n    adtype::ADTypes.AbstractADType=DEFAULT_ADTYPE,\n    algorithm::AdvancedVI.AbstractVariationalAlgorithm = KLMinRepGradProxDescent(\n        adtype; n_samples=10\n    ),\n    show_progress::Bool = Turing.PROGRESS[],\n    kwargs...\n)\n\nApproximate the target model via the variational inference algorithm algorithm by starting from the initial variational approximation q. This is a thin wrapper around AdvancedVI.optimize.\n\nIf the chosen variational inference algorithm operates in an unconstrained space, then the provided initial variational approximation q must be a Bijectors.TransformedDistribution of an unconstrained distribution. For example, the initialization supplied by  q_meanfield_gaussian,q_fullrank_gaussian, q_locationscale.\n\nThe default algorithm, KLMinRepGradProxDescent (relevant docs), assumes q uses AdvancedVI.MvLocationScale, which can be constructed by invoking q_fullrank_gaussian or q_meanfield_gaussian. For other variational families, refer to the documentation of AdvancedVI to determine the best algorithm and other options.\n\nArguments\n\nmodel: The target DynamicPPL.Model.\nq: The initial variational approximation.\nmax_iter: Maximum number of steps.\nAny additional arguments are passed on to AdvancedVI.optimize.\n\nKeyword Arguments\n\nadtype: Automatic differentiation backend to be applied to the log-density. The default value for algorithm also uses this backend for differentiating the variational objective.\nalgorithm: Variational inference algorithm. The default is KLMinRepGradProxDescent, please refer to AdvancedVI docs for all the options.\nshow_progress: Whether to show the progress bar.\nunconstrained: Whether to transform the posterior to be unconstrained for running the variational inference algorithm. If true, then the output q will be wrapped into a Bijectors.TransformedDistribution with the transformation matching the support of the posterior. The default value depends on the chosen algorithm.\nAny additional keyword arguments are passed on to AdvancedVI.optimize.\n\nSee the docs of AdvancedVI.optimize for additional keyword arguments.\n\nReturns\n\nq: Output variational distribution of algorithm.\nstate: Collection of states used by algorithm. This can be used to resume from a past call to vi.\ninfo: Information generated while executing algorithm.\n\n\n\n\n\n","category":"method"}]
}
