<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Inference · Turing</title><meta name="title" content="Inference · Turing"/><meta property="og:title" content="Inference · Turing"/><meta property="twitter:title" content="Inference · Turing"/><meta name="description" content="Documentation for Turing."/><meta property="og:description" content="Documentation for Turing."/><meta property="twitter:description" content="Documentation for Turing."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body>
<!-- NAVBAR START -->
<style>
    @import url('https://fonts.googleapis.com/css2?family=Source+Sans+Pro&display=swap');

    /* Documenter.jl CSS Overrides */
    html {
        scroll-padding-top: calc(var(--navbar-height) + 1rem);
    }
    .docs-sidebar, #documenter {
        margin-top: var(--navbar-height);
    }
    .docs-version-selector {
        margin-bottom: 60px !important;
    }
    @media screen and (max-width: 1056px) {
        .docs-version-selector {
            margin-bottom: 60px !important;
        }
        .docs-sidebar {
            margin-top: 0 !important;
        }
    }
    /* End of Documenter.jl Tweaks */

    /* Color and Font Variables */
    :root {
        --heading-color: #6c757d;
        --item-color: rgb(165, 165, 165);
        --primary-bg: white;
        --hover-color: #8faad2;
        --deprecated-bg: #ff4d4d;
        --deprecated-text: white;
        --icon-color: #6c757d;
        --shadow-color: rgba(0, 0, 0, 0.1);
        --dropdown-hover-bg: #e9ecef;
        
        /* Typography */
        --font-family: "Source Sans Pro", -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
        --nav-link-font-size: 1.0625rem;
        --turing-title-font-size: 21.25px;
        --icon-font-size: 1.25rem;
        --dropdown-arrow-font-size: 0.6875rem;
        --badge-font-size: 0.75rem;

        /* Sizing and Spacing */
        --navbar-height: 3.75rem;
        --logo-height: 31px;
        --logo-width: auto;
        --logo-padding-top: 7px;
        --logo-margin-left: 0.8rem;
        --title-margin-left: 0.4px;
        --title-nav-spacing: 1.1rem;
        --nav-item-margin-left: 1.3rem;
        --icon-margin-left: 1rem;
        --dropdown-padding: 1.875rem;
        --dropdown-item-width: 12.5rem;
        --dropdown-subitem-width: 15.625rem;
        --dropdown-subitem-padding: 0.125rem 0.625rem;
    }

    /* Dark Theme Variable Overrides */
    html.theme--documenter-dark {
        --heading-color: #e0e0e0;
        --item-color: #bdbdbd;
        --primary-bg: #1f2424;
        --hover-color: #ffffff;
        --icon-color: #e0e0e0;
        --shadow-color: rgba(255, 255, 255, 0.1);
        --dropdown-hover-bg: #424242;
    }

    /* Catppuccin Theme Overrides */
    html.theme--catppuccin-latte {
        --heading-color: #4c4f69;
        --primary-bg: #eff1f5;
        --icon-color: #4c4f69;
        --shadow-color: rgba(0, 0, 0, 0.1);
        --dropdown-hover-bg: #e6e9ef;
    }
    html.theme--catppuccin-frappe {
        --heading-color: #c6d0f5;
        --primary-bg: #303446;
        --icon-color: #c6d0f5;
        --shadow-color: rgba(255, 255, 255, 0.1);
        --dropdown-hover-bg: #51576d;
    }
    html.theme--catppuccin-macchiato {
        --heading-color: #cad3f5;
        --primary-bg: #24273a;
        --icon-color: #cad3f5;
        --shadow-color: rgba(255, 255, 255, 0.1);
        --dropdown-hover-bg: #494d64;
    }
    html.theme--catppuccin-mocha {
        --heading-color: #cad3f5;
        --primary-bg: #1e1e2e;
        --icon-color: #cad3f5;
        --shadow-color: rgba(255, 255, 255, 0.1);
        --dropdown-hover-bg: #45475a;
    }


    /* Main Navigation Bar */
    .ext-navigation {
        font-family: var(--font-family);
        position: fixed;
        height: var(--navbar-height);
        top: 0;
        width: 100%;
        background-color: var(--primary-bg);
        z-index: 1000;
        box-shadow: 0 2px 4px var(--shadow-color);
        display: flex;
        align-items: center;
        padding: 0 1.0625rem;
        transition: transform 0.3s, background-color 0.3s;
    }

    nav.ext-navigation .ext-navbar-logo {
        margin-left: var(--logo-margin-left);
        height: auto;
        max-height: var(--logo-height);
        width: auto;
        padding-top: var(--logo-padding-top);
    }
    
    /* Theme-aware logo text color */
    .ext-navbar-logo .logo-text {
        fill: var(--heading-color);
    }
    
    .ext-navbar-title {
        color: var(--heading-color) !important;
        font-size: var(--turing-title-font-size) !important;
        margin-left: var(--title-margin-left);
        text-decoration: none;
        transition: color 0.2s ease;
    }
    
    .ext-navbar-title:hover {
        color: var(--hover-color) !important;
    }

    .ext-nav-links {
        display: flex;
        align-items: center;
        list-style-type: none;
        margin: 0;
        padding: 0;
        flex-grow: 1;
        margin-left: var(--title-nav-spacing);
    }

    .ext-nav-links li:first-child {
        margin-left: 0 !important;
    }

    .ext-nav-links li {
        margin-left: var(--nav-item-margin-left) !important;
    }

    .ext-nav-link {
        color: var(--heading-color) !important;
        text-decoration: none;
        font-size: var(--nav-link-font-size) !important;
        transition: color 0.2s ease;
        cursor: pointer;
    }

    .ext-nav-link:hover,
    .ext-navbar-item-single a:hover,
    .ext-navbar-icons a:hover {
        color: var(--hover-color) !important;
    }

    .ext-navbar-item-single a {
        color: var(--heading-color) !important;
    }
    
    .ext-navbar-icons {
        display: flex;
        align-items: center;
    }

    .ext-navbar-icons a {
        color: var(--icon-color) !important;
        font-size: var(--icon-font-size) !important;
        transition: color 0.2s ease;
        margin-left: var(--icon-margin-left);
    }

    .ext-menu-toggle {
        display: none;
        font-size: 1.5rem;
        color: var(--heading-color);
        cursor: pointer;
    }

    .ext-dropdown {
        display: none;
        grid-template-columns: 1fr 1fr 1fr 1fr;
        padding: var(--dropdown-padding);
        position: absolute;
        top: var(--navbar-height);
        width: 100%;
        left: 0;
        background-color: var(--primary-bg);
        line-height: 1.875rem;
        opacity: 0;
        transition: opacity 0.3s ease-in-out, transform 0.3s ease-in-out, background-color 0.3s;
        transform: translateY(-0.625rem);
        box-shadow: 0 4px 6px var(--shadow-color);
    }

    #library-handler::after {
        content: "▼";
        font-size: var(--dropdown-arrow-font-size);
        margin-left: 0.3125rem;
        transition: transform 0.3s ease-in-out;
    }

    #library-handler.open::after {
        content: "▲";
    }

    .ext-dropdown.show {
        display: grid;
        opacity: 1;
        transform: translateY(0);
    }

    .ext-dropdown ul {
        width: var(--dropdown-item-width);
        margin-bottom: 1.25rem;
    }

    .ext-dropdown ul li {
        text-align: left;
        display: flex;
        align-items: center;
    }

    .ext-dropdown ul a li {
        color: var(--item-color);
        width: var(--dropdown-subitem-width);
        border-radius: 3px;
        padding: var(--dropdown-subitem-padding);
        transition: background-color 0.2s ease;
    }

    .ext-dropdown ul a li:hover {
        background-color: var(--dropdown-hover-bg);
    }

    .ext-dropdown-item-heading {
        color: var(--heading-color);
        text-align: center;
    }

    .deprecated-badge {
        background-color: var(--deprecated-bg);
        color: var(--deprecated-text);
        font-size: var(--badge-font-size);
        padding: .1rem;
        border-radius: 3px;
        margin-left: 0.5rem;
        line-height: 1;
    }

    @media (max-width: 966px) {
        .ext-dropdown {
            grid-template-columns: 1fr 1fr 1fr;
        }
    }

    @media (max-width: 768px) {
        .ext-nav-links {
            display: none;
            flex-direction: column;
            align-items: center;
            width: 100%;
            background-color: var(--primary-bg);
            position: absolute;
            top: var(--navbar-height);
            left: 0;
            padding: 0.625rem 0;
            height: auto;
            overflow-y: auto;
            box-shadow: 0 4px 6px var(--shadow-color);
            margin-left: 0;
        }

        .ext-nav-links.show {
            display: flex;
        }

        .ext-nav-links li {
            margin: 0.625rem 0 !important;
            text-align: center;
        }
        
        .ext-menu-toggle {
            display: block;
            margin-left: auto;
        }

        .ext-navigation.hide {
            transform: translateY(calc(-1 * var(--navbar-height)));
        }

        .ext-dropdown {
            position: static;
            display: block;
            opacity: 1;
            transform: none;
            box-shadow: none;
            grid-template-columns: 1fr;
            padding: 0.625rem;
            text-align: center;
        }

        .ext-dropdown ul {
            width: auto;
            display: inline-block;
            margin: 0 auto 0.3125rem;
            text-align: left;
        }
    }
</style>
<nav class="ext-navigation">
    <a href="https://turinglang.org/">
        <svg width="4333" height="1145" viewBox="0 0 4333 1145" fill="none" xmlns="http://www.w3.org/2000/svg" class="ext-navbar-logo">
            <path class="logo-text" d="M0.44603 193.181V66.9868H663.471V193.181H406.62V898H257.297V193.181H0.44603ZM1097.24 635.874V274.74H1244.13V898H1101.7V787.225H1095.21C1081.14 822.121 1058.01 850.66 1025.82 872.842C993.902 895.024 954.542 906.115 907.744 906.115C866.896 906.115 830.783 897.053 799.403 878.929C768.295 860.534 743.948 833.889 726.365 798.993C708.782 763.826 699.99 721.356 699.99 671.581V274.74H846.878V648.858C846.878 688.353 857.699 719.733 879.34 742.997C900.981 766.261 929.385 777.893 964.551 777.893C986.192 777.893 1007.16 772.618 1027.45 762.068C1047.73 751.518 1064.37 735.828 1077.35 714.999C1090.61 693.899 1097.24 667.524 1097.24 635.874ZM1395.17 898V274.74H1537.6V378.617H1544.09C1555.45 342.639 1574.93 314.911 1602.52 295.434C1630.38 275.687 1662.17 265.813 1697.88 265.813C1705.99 265.813 1715.05 266.219 1725.06 267.031C1735.34 267.572 1743.86 268.518 1750.63 269.871V404.992C1744.4 402.828 1734.53 400.934 1721 399.311C1707.75 397.417 1694.9 396.471 1682.46 396.471C1655.68 396.471 1631.6 402.287 1610.23 413.919C1589.13 425.28 1572.49 441.105 1560.32 461.393C1548.15 481.682 1542.06 505.081 1542.06 531.591V898H1395.17ZM1848.21 898V274.74H1995.1V898H1848.21ZM1922.06 186.283C1898.8 186.283 1878.78 178.573 1862.01 163.154C1845.24 147.464 1836.85 128.664 1836.85 106.752C1836.85 84.5701 1845.24 65.7695 1862.01 50.3503C1878.78 34.6606 1898.8 26.8158 1922.06 26.8158C1945.6 26.8158 1965.61 34.6606 1982.12 50.3503C1998.89 65.7695 2007.27 84.5701 2007.27 106.752C2007.27 128.664 1998.89 147.464 1982.12 163.154C1965.61 178.573 1945.6 186.283 1922.06 186.283ZM2293.04 532.809V898H2146.15V274.74H2286.54V380.646H2293.85C2308.18 345.75 2331.04 318.022 2362.42 297.463C2394.07 276.904 2433.16 266.625 2479.69 266.625C2522.7 266.625 2560.17 275.822 2592.09 294.217C2624.28 312.612 2649.17 339.257 2666.75 374.153C2684.6 409.049 2693.39 451.385 2693.12 501.159V898H2546.24V523.882C2546.24 482.223 2535.41 449.626 2513.77 426.092C2492.4 402.557 2462.78 390.79 2424.91 390.79C2399.21 390.79 2376.35 396.471 2356.34 407.832C2336.59 418.923 2321.03 435.019 2309.67 456.119C2298.58 477.218 2293.04 502.782 2293.04 532.809ZM3113.5 1144.71C3060.75 1144.71 3015.44 1137.54 2977.57 1123.2C2939.7 1109.13 2909.26 1090.2 2886.27 1066.39C2863.28 1042.59 2847.32 1016.21 2838.39 987.269L2970.67 955.213C2976.62 967.386 2985.28 979.424 2996.64 991.327C3008 1003.5 3023.28 1013.51 3042.49 1021.35C3061.97 1029.47 3086.45 1033.53 3115.93 1033.53C3157.59 1033.53 3192.08 1023.38 3219.4 1003.09C3246.73 983.076 3260.39 950.074 3260.39 904.087V786.008H3253.08C3245.51 801.157 3234.42 816.711 3219.81 832.671C3205.47 848.632 3186.4 862.022 3162.6 872.842C3139.06 883.663 3109.44 889.073 3073.73 889.073C3025.85 889.073 2982.44 877.847 2943.48 855.394C2904.8 832.671 2873.96 798.857 2850.97 753.952C2828.24 708.777 2816.88 652.24 2816.88 584.341C2816.88 515.902 2828.24 458.147 2850.97 411.078C2873.96 363.739 2904.93 327.896 2943.89 303.55C2982.84 278.933 3026.26 266.625 3074.14 266.625C3110.66 266.625 3140.69 272.847 3164.22 285.29C3188.03 297.463 3206.96 312.206 3221.03 329.519C3235.09 346.561 3245.78 362.657 3253.08 377.805H3261.2V274.74H3406.06V908.144C3406.06 961.435 3393.34 1005.53 3367.92 1040.42C3342.49 1075.32 3307.73 1101.43 3263.63 1118.74C3219.54 1136.05 3169.5 1144.71 3113.5 1144.71ZM3114.72 773.835C3145.83 773.835 3172.34 766.261 3194.25 751.112C3216.16 735.963 3232.79 714.187 3244.16 685.783C3255.52 657.379 3261.2 623.295 3261.2 583.53C3261.2 544.305 3255.52 509.95 3244.16 480.465C3233.07 450.979 3216.56 428.12 3194.65 411.89C3173.01 395.389 3146.37 387.138 3114.72 387.138C3081.98 387.138 3054.66 395.659 3032.75 412.701C3010.84 429.744 2994.34 453.143 2983.25 482.899C2972.16 512.385 2966.61 545.929 2966.61 583.53C2966.61 621.672 2972.16 655.08 2983.25 683.754C2994.61 712.158 3011.25 734.34 3033.16 750.3C3055.34 765.99 3082.53 773.835 3114.72 773.835ZM3647.08 906.927C3622.47 906.927 3601.37 898.271 3583.78 880.958C3566.2 863.645 3557.54 842.545 3557.82 817.658C3557.54 793.312 3566.2 772.482 3583.78 755.17C3601.37 737.857 3622.47 729.2 3647.08 729.2C3670.89 729.2 3691.58 737.857 3709.17 755.17C3727.02 772.482 3736.08 793.312 3736.35 817.658C3736.08 834.159 3731.75 849.173 3723.37 862.698C3715.25 876.224 3704.43 887.044 3690.91 895.16C3677.65 903.004 3663.04 906.927 3647.08 906.927ZM3888.01 274.74H4034.9V933.708C4034.9 978.613 4026.38 1015.67 4009.33 1044.89C3992.29 1074.1 3967.67 1095.88 3935.48 1110.22C3903.29 1124.55 3864.2 1131.72 3818.22 1131.72C3812.81 1131.72 3807.8 1131.59 3803.2 1131.32C3798.6 1131.32 3793.6 1131.18 3788.19 1130.91V1011.21C3792.25 1011.48 3795.9 1011.62 3799.15 1011.62C3802.39 1011.89 3805.77 1012.02 3809.29 1012.02C3837.42 1012.02 3857.58 1005.12 3869.75 991.327C3881.92 977.801 3888.01 957.918 3888.01 931.679V274.74ZM3961.05 186.283C3937.51 186.283 3917.36 178.573 3900.59 163.154C3884.09 147.464 3875.84 128.664 3875.84 106.752C3875.84 84.5701 3884.09 65.7695 3900.59 50.3503C3917.36 34.6606 3937.51 26.8158 3961.05 26.8158C3984.31 26.8158 4004.19 34.6606 4020.7 50.3503C4037.47 65.7695 4045.85 84.5701 4045.85 106.752C4045.85 128.664 4037.47 147.464 4020.7 163.154C4004.19 178.573 3984.31 186.283 3961.05 186.283ZM4332.83 66.9868V898H4185.94V66.9868H4332.83Z" fill="currentColor"/>
            <path d="M4076 108.5C4076 168.424 4027.42 217 3967.5 217C3907.58 217 3859 168.424 3859 108.5C3859 48.5762 3907.58 0 3967.5 0C4027.42 0 4076 48.5762 4076 108.5Z" fill="#389725"/>
            <path d="M3755 814.5C3755 874.424 3706.42 923 3646.5 923C3586.58 923 3538 874.424 3538 814.5C3538 754.576 3586.58 706 3646.5 706C3706.42 706 3755 754.576 3755 814.5Z" fill="#9457B1"/>
            <path d="M2030 108.5C2030 168.424 1981.42 217 1921.5 217C1861.58 217 1813 168.424 1813 108.5C1813 48.5762 1861.58 0 1921.5 0C1981.42 0 2030 48.5762 2030 108.5Z" fill="#CA3B33"/>
        </svg>
    </a>
    <!-- <a class="ext-navbar-title" href="https://turinglang.org/">Turing.jl</a> -->
    
    <ul class="ext-nav-links">
        <li><a class="ext-nav-link" href="https://turinglang.org/docs/getting-started/">Get Started</a></li>
        <li><a class="ext-nav-link" href="https://turinglang.org/docs/tutorials/">Tutorials</a></li>
        <li><a class="ext-nav-link" href="https://turinglang.org/docs/faq/">FAQ</a></li>
        <li>
            <p class="ext-nav-link" id="library-handler">Libraries</p>
            <div class="ext-dropdown" id="ext-dropdown-items">
                <ul>
                    <li class="ext-dropdown-item-heading">Modelling Languages</li>
                    <a href="https://turinglang.org/DynamicPPL.jl/"><li>DynamicPPL</li></a>
                    <a href="https://turinglang.org/JuliaBUGS.jl/"><li>JuliaBUGS</li></a>
                    <a href="https://turinglang.org/TuringGLM.jl/"><li>TuringGLM</li></a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading">MCMC</li>
                    <a href="https://turinglang.org/AdvancedHMC.jl/"><li>AdvancedHMC</li></a>
                    <a href="https://turinglang.org/AbstractMCMC.jl/"><li>AbstractMCMC</li></a>
                    <a href="https://github.com/theogf/ThermodynamicIntegration.jl"><li>ThermodynamicIntegration</li></a>
                    <a href="https://turinglang.org/AdvancedPS.jl/"><li>AdvancedPS</li></a>
                    <a href="https://turinglang.org/SliceSampling.jl/"><li>SliceSampling</li></a>
                    <a href="https://turinglang.org/EllipticalSliceSampling.jl/"><li>EllipticalSliceSampling</li></a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading">Diagnostics</li>
                    <a href="https://turinglang.org/MCMCChains.jl/"><li>MCMCChains</li></a>
                    <a href="https://turinglang.org/MCMCDiagnosticTools.jl/"><li>MCMCDiagnosticTools</li></a>
                    <a href="https://turinglang.org/ParetoSmooth.jl/"><li>ParetoSmooth</li></a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading">Gaussian Processes</li>
                    <a href="https://juliagaussianprocesses.github.io/AbstractGPs.jl/"><li>AbstractGPs</li></a>
                    <a href="https://juliagaussianprocesses.github.io/KernelFunctions.jl/"><li>KernelFunctions</li></a>
                    <a href="https://juliagaussianprocesses.github.io/ApproximateGPs.jl/"><li>ApproximateGPs</li></a>
                </ul>
                <ul><li class="ext-dropdown-item-heading ext-navbar-item-single"><a href="https://turinglang.org/Bijectors.jl/">Bijectors</a></li></ul>
                <ul><li class="ext-dropdown-item-heading ext-navbar-item-single"><a href="https://turinglang.org/TuringCallbacks.jl/">TuringCallbacks</a></li></ul>
                <ul><li class="ext-dropdown-item-heading ext-navbar-item-single"><a href="https://turinglang.org/Deprecated/TuringBenchmarking/">TuringBenchmarking</a><span class="deprecated-badge">Deprecated</span></li></ul>
            </div>
        </li>
        <li><a class="ext-nav-link" href="https://turinglang.org/news/">News</a></li>
        <li><a class="ext-nav-link" href="https://turinglang.org/team/">Team</a></li>
    </ul>

    <div class="ext-navbar-icons">
        <a href="https://x.com/TuringLang" aria-label="Turing on X"><i class="fa-brands fa-x-twitter"></i></a>
        <a href="https://discourse.julialang.org/c/domain/probprog/48" aria-label="Turing on Discourse"><i class="fa-brands fa-discourse"></i></a>
        <a href="https://julialang.slack.com/archives/CCYDC34A0" aria-label="Turing on Slack"><i class="fa-brands fa-slack"></i></a>
        <a href="https://github.com/TuringLang/" aria-label="Turing.jl on GitHub"><i class="fa-brands fa-github"></i></a>
    </div>

    <span class="ext-menu-toggle"><i class="fa-solid fa-bars"></i></span>
</nav>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        const menuToggle = document.querySelector(".ext-menu-toggle");
        const navLinks = document.querySelector(".ext-nav-links");
        const nav = document.querySelector(".ext-navigation");
        const libraryHandler = document.getElementById("library-handler");
        const dropdownContainer = document.getElementById("ext-dropdown-items");
        let lastScrollY = window.scrollY;

        function closeDropdown() {
            if (dropdownContainer.classList.contains("show")) {
                libraryHandler.classList.remove("open");
                dropdownContainer.classList.remove("show");
                setTimeout(() => {
                    if (!dropdownContainer.classList.contains("show")) {
                        dropdownContainer.style.display = "none";
                    }
                }, 300);
            }
        }

        function openDropdown() {
            dropdownContainer.style.display = "grid";
            libraryHandler.classList.add("open");
            setTimeout(() => {
                dropdownContainer.classList.add("show");
            }, 10);
        }

        function setAppropriateHeight() {
            if (window.innerWidth <= 768) {
                const viewportHeight = window.innerHeight;
                const navHeight = nav.offsetHeight;
                navLinks.style.maxHeight = `${viewportHeight - navHeight}px`;
                navLinks.style.overflowY = "auto";
            } else {
                navLinks.style.maxHeight = "";
                navLinks.style.overflowY = "";
            }
        }

        menuToggle.addEventListener("click", (event) => {
            event.stopPropagation();
            navLinks.classList.toggle("show");
            if (navLinks.classList.contains("show")) {
                setAppropriateHeight();
                closeDropdown();
                dropdownContainer.style.display = "none";
            }
        });

        libraryHandler.addEventListener("click", (event) => {
            event.stopPropagation();
            event.preventDefault();
            if (dropdownContainer.classList.contains("show")) {
                closeDropdown();
            } else {
                openDropdown();
            }
            setAppropriateHeight();
        });

        // Close all menus if a click is registered outside the navigation bar.
        document.addEventListener("click", (event) => {
            if (!nav.contains(event.target)) {
                navLinks.classList.remove("show");
                closeDropdown();
            }
        });

        // Hide navigation bar on scroll down in mobile view.
        window.addEventListener("scroll", () => {
            if (window.innerWidth <= 768) {
                if (window.scrollY > lastScrollY && window.scrollY > nav.offsetHeight){
                    nav.classList.add("hide");
                } else {
                    nav.classList.remove("hide");
                }
                lastScrollY = window.scrollY;
            }
        });

        window.addEventListener("resize", setAppropriateHeight);
    });
</script>
<!-- NAVBAR END -->


<div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Turing</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../">API</a></li><li><span class="tocitem">Submodule APIs</span><ul><li class="is-active"><a class="tocitem" href>Inference</a></li><li><a class="tocitem" href="../Optimisation/">Optimisation</a></li><li><a class="tocitem" href="../Variational/">Variational </a></li><li><a class="tocitem" href="../RandomMeasures/">RandomMeasures </a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Submodule APIs</a></li><li class="is-active"><a href>Inference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Inference</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/TuringLang/Turing.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/TuringLang/Turing.jl/blob/main/docs/src/api/Inference.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="API:-Turing.Inference"><a class="docs-heading-anchor" href="#API:-Turing.Inference">API: <code>Turing.Inference</code></a><a id="API:-Turing.Inference-1"></a><a class="docs-heading-anchor-permalink" href="#API:-Turing.Inference" title="Permalink"></a></h1><article><details class="docstring" open="true"><summary id="Turing.Inference.CSMC"><a class="docstring-binding" href="#Turing.Inference.CSMC"><code>Turing.Inference.CSMC</code></a> — <span class="docstring-category">Type</span></summary><section><div><p>CSMC(...)</p><p>Equivalent to <a href="#Turing.Inference.PG"><code>PG</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/particle_mcmc.jl#L239-L243">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.ESS"><a class="docstring-binding" href="#Turing.Inference.ESS"><code>Turing.Inference.ESS</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">ESS</code></pre><p>Elliptical slice sampling algorithm.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; @model function gdemo(x)
           m ~ Normal()
           x ~ Normal(m, 0.5)
       end
gdemo (generic function with 2 methods)

julia&gt; sample(gdemo(1.0), ESS(), 1_000) |&gt; mean
Mean

│ Row │ parameters │ mean     │
│     │ Symbol     │ Float64  │
├─────┼────────────┼──────────┤
│ 1   │ m          │ 0.824853 │</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/ess.jl#L1-L22">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.Emcee"><a class="docstring-binding" href="#Turing.Inference.Emcee"><code>Turing.Inference.Emcee</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">Emcee(n_walkers::Int, stretch_length=2.0)</code></pre><p>Affine-invariant ensemble sampling algorithm.</p><p><strong>Reference</strong></p><p>Foreman-Mackey, D., Hogg, D. W., Lang, D., &amp; Goodman, J. (2013). emcee: The MCMC Hammer. Publications of the Astronomical Society of the Pacific, 125 (925), 306. https://doi.org/10.1086/670067</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/emcee.jl#L5-L15">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.ExternalSampler"><a class="docstring-binding" href="#Turing.Inference.ExternalSampler"><code>Turing.Inference.ExternalSampler</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">ExternalSampler{Unconstrained,S&lt;:AbstractSampler,AD&lt;:ADTypes.AbstractADType}</code></pre><p>Represents a sampler that does not have a custom implementation of <code>AbstractMCMC.step(rng, ::DynamicPPL.Model, spl)</code>.</p><p>The <code>Unconstrained</code> type-parameter is to indicate whether the sampler requires unconstrained space.</p><p><strong>Fields</strong></p><ul><li><p><code>sampler::AbstractMCMC.AbstractSampler</code>: the sampler to wrap</p></li><li><p><code>adtype::ADTypes.AbstractADType</code>: the automatic differentiation (AD) backend to use</p></li></ul><p><strong>Turing.jl&#39;s interface for external samplers</strong></p><p>If you implement a new <code>MySampler &lt;: AbstractSampler</code> and want it to work with Turing.jl models, there are two options:</p><ol><li><p>Directly implement the <code>AbstractMCMC.step</code> methods for <code>DynamicPPL.Model</code>. That is to say, implement <code>AbstractMCMC.step(rng::Random.AbstractRNG, model::DynamicPPL.Model, sampler::MySampler; kwargs...)</code> and related methods. This is the most powerful option and is what Turing.jl&#39;s in-house samplers do. Implementing this means that you can directly call <code>sample(model, MySampler(), N)</code>.</p></li><li><p>Implement a generic <code>AbstractMCMC.step</code> method for <code>AbstractMCMC.LogDensityModel</code> (the same signature as above except that <code>model::AbstractMCMC.LogDensityModel</code>). This struct wraps an object that obeys the LogDensityProblems.jl interface, so your <code>step</code> implementation does not need to know anything about Turing.jl or DynamicPPL.jl. To use this with Turing.jl, you will need to wrap your sampler: <code>sample(model, externalsampler(MySampler()), N)</code>.</p></li></ol><p>This section describes the latter.</p><p><code>MySampler</code> <strong>must</strong> implement the following methods:</p><ul><li><p><code>AbstractMCMC.step</code> (the main function for taking a step in MCMC sampling; this is documented in AbstractMCMC.jl). This function must return a tuple of two elements, a &#39;transition&#39; and a &#39;state&#39;.</p></li><li><p><code>AbstractMCMC.getparams(external_state)</code>: How to extract the parameters from the <strong>state</strong> returned by your sampler (i.e., the <strong>second</strong> return value of <code>step</code>). For your sampler to work with Turing.jl, this function should return a Vector of parameter values. Note that this function does not need to perform any linking or unlinking; Turing.jl will take care of this for you. You should return the parameters <em>exactly</em> as your sampler sees them.</p></li><li><p><code>AbstractMCMC.getstats(external_state)</code>: Extract sampler statistics corresponding to this iteration from the <strong>state</strong> returned by your sampler (i.e., the <strong>second</strong> return value of <code>step</code>). For your sampler to work with Turing.jl, this function should return a <code>NamedTuple</code>. If there are no statistics to return, return <code>NamedTuple()</code>.</p><p>Note that <code>getstats</code> should not include log-probabilities as these will be recalculated by Turing automatically for you.</p></li></ul><p>Notice that both of these functions take the <strong>state</strong> as input, not the <strong>transition</strong>. In other words, the transition is completely useless for the external sampler interface. This is in line with long-term plans for removing transitions from AbstractMCMC.jl and only using states.</p><p>There are a few more optional functions which you can implement to improve the integration with Turing.jl:</p><ul><li><p><code>AbstractMCMC.requires_unconstrained_space(::MySampler)</code>: If your sampler requires unconstrained space, you should return <code>true</code>. This tells Turing to perform linking on the VarInfo before evaluation, and ensures that the parameter values passed to your sampler will always be in unconstrained (Euclidean) space.</p></li><li><p><code>Turing.Inference.isgibbscomponent(::MySampler)</code>: If you want to disallow your sampler from a component in Turing&#39;s Gibbs sampler, you should make this evaluate to <code>false</code>. Note that the default is <code>true</code>, so you should only need to implement this in special cases.</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/external_sampler.jl#L1-L68">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.Gibbs"><a class="docstring-binding" href="#Turing.Inference.Gibbs"><code>Turing.Inference.Gibbs</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">Gibbs</code></pre><p>A type representing a Gibbs sampler.</p><p><strong>Constructors</strong></p><p><code>Gibbs</code> needs to be given a set of pairs of variable names and samplers. Instead of a single variable name per sampler, one can also give an iterable of variables, all of which are sampled by the same component sampler.</p><p>Each variable name can be given as either a <code>Symbol</code> or a <code>VarName</code>.</p><p>Some examples of valid constructors are:</p><pre><code class="language-julia hljs">Gibbs(:x =&gt; NUTS(), :y =&gt; MH())
Gibbs(@varname(x) =&gt; NUTS(), @varname(y) =&gt; MH())
Gibbs((@varname(x), :y) =&gt; NUTS(), :z =&gt; MH())</code></pre><p><strong>Fields</strong></p><ul><li><p><code>varnames::NTuple{N, AbstractVector{&lt;:AbstractPPL.VarName}} where N</code>: varnames representing variables for each sampler</p></li><li><p><code>samplers::NTuple{N, Any} where N</code>: samplers for each entry in <code>varnames</code></p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/gibbs.jl#L239-L261">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.GibbsConditional"><a class="docstring-binding" href="#Turing.Inference.GibbsConditional"><code>Turing.Inference.GibbsConditional</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">GibbsConditional(get_cond_dists)</code></pre><p>A Gibbs component sampler that samples variables according to user-provided analytical conditional posterior distributions.</p><p>When using Gibbs sampling, sometimes one may know the analytical form of the posterior for a given variable, given the conditioned values of the other variables. In such cases one can use <code>GibbsConditional</code> as a component sampler to to sample from these known conditionals directly, avoiding any MCMC methods. One does so with</p><pre><code class="language-julia hljs">sampler = Gibbs(
    (@varname(var1), @varname(var2)) =&gt; GibbsConditional(get_cond_dists),
    other samplers go here...
)</code></pre><p>Here <code>get_cond_dists(c::Dict{&lt;:VarName})</code> should be a function that takes a <code>Dict</code> mapping the conditioned variables (anything other than <code>var1</code> and <code>var2</code>) to their values, and returns the conditional posterior distributions for <code>var1</code> and <code>var2</code>. You may, of course, have any number of variables being sampled as a block in this manner, we only use two as an example. The return value of <code>get_cond_dists</code> should be one of the following:</p><ul><li>A single <code>Distribution</code>, if only one variable is being sampled.</li><li>An <code>AbstractDict{&lt;:VarName,&lt;:Distribution}</code> that maps the variables being sampled to their conditional posteriors E.g. <code>Dict(@varname(var1) =&gt; dist1, @varname(var2) =&gt; dist2)</code>.</li><li>A <code>NamedTuple</code> of <code>Distribution</code>s, which is like the <code>AbstractDict</code> case but can be used if all the variable names are single <code>Symbol</code>s, and may be more performant. E.g. <code>(; var1=dist1, var2=dist2)</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs"># Define a model
@model function inverse_gdemo(x)
    precision ~ Gamma(2, inv(3))
    std = sqrt(1 / precision)
    m ~ Normal(0, std)
    for i in eachindex(x)
        x[i] ~ Normal(m, std)
    end
end

# Define analytical conditionals. See
# https://en.wikipedia.org/wiki/Conjugate_prior#When_likelihood_function_is_a_continuous_distribution
function cond_precision(c)
    a = 2.0
    b = 3.0
    # We use AbstractPPL.getvalue instead of indexing into `c` directly to guard against
    # issues where e.g. you try to get `c[@varname(x[1])]` but only `@varname(x)` is present
    # in `c`. `getvalue` handles that gracefully, `getindex` doesn&#39;t. In this case
    # `getindex` would suffice, but `getvalue` is good practice.
    m = AbstractPPL.getvalue(c, @varname(m))
    x = AbstractPPL.getvalue(c, @varname(x))
    n = length(x)
    a_new = a + (n + 1) / 2
    b_new = b + sum(abs2, x .- m) / 2 + m^2 / 2
    return Gamma(a_new, 1 / b_new)
end

function cond_m(c)
    precision = AbstractPPL.getvalue(c, @varname(precision))
    x = AbstractPPL.getvalue(c, @varname(x))
    n = length(x)
    m_mean = sum(x) / (n + 1)
    m_var = 1 / (precision * (n + 1))
    return Normal(m_mean, sqrt(m_var))
end

# Sample using GibbsConditional
model = inverse_gdemo([1.0, 2.0, 3.0])
chain = sample(model, Gibbs(
    :precision =&gt; GibbsConditional(cond_precision),
    :m =&gt; GibbsConditional(cond_m)
), 1000)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/gibbs_conditional.jl#L1-L77">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.GibbsContext"><a class="docstring-binding" href="#Turing.Inference.GibbsContext"><code>Turing.Inference.GibbsContext</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">GibbsContext(target_varnames, global_varinfo, context)</code></pre><p>A context used in the implementation of the Turing.jl Gibbs sampler.</p><p>There will be one <code>GibbsContext</code> for each iteration of a component sampler.</p><p><code>target_varnames</code> is a a tuple of <code>VarName</code>s that the current component sampler is sampling. For those <code>VarName</code>s, <code>GibbsContext</code> will just pass <code>tilde_assume!!</code> calls to its child context. For other variables, their values will be fixed to the values they have in <code>global_varinfo</code>.</p><p><strong>Fields</strong></p><ul><li><code>target_varnames</code>: the VarNames being sampled</li></ul><ul><li><code>global_varinfo</code>: a <code>Ref</code> to the global <code>AbstractVarInfo</code> object that holds values for all variables, both those fixed and those being sampled. We use a <code>Ref</code> because this field may need to be updated if new variables are introduced.</li></ul><ul><li><code>context</code>: the child context that tilde calls will eventually be passed onto.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/gibbs.jl#L36-L50">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.HMC"><a class="docstring-binding" href="#Turing.Inference.HMC"><code>Turing.Inference.HMC</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">HMC(ϵ::Float64, n_leapfrog::Int; adtype::ADTypes.AbstractADType = AutoForwardDiff())</code></pre><p>Hamiltonian Monte Carlo sampler with static trajectory.</p><p><strong>Arguments</strong></p><ul><li><code>ϵ</code>: The leapfrog step size to use.</li><li><code>n_leapfrog</code>: The number of leapfrog steps to use.</li><li><code>adtype</code>: The automatic differentiation (AD) backend.   If not specified, <code>ForwardDiff</code> is used, with its <code>chunksize</code> automatically determined.</li></ul><p><strong>Usage</strong></p><pre><code class="language-julia hljs">HMC(0.05, 10)</code></pre><p><strong>Tips</strong></p><p>If you are receiving gradient errors when using <code>HMC</code>, try reducing the leapfrog step size <code>ϵ</code>, e.g.</p><pre><code class="language-julia hljs"># Original step size
sample(gdemo([1.5, 2]), HMC(0.1, 10), 1000)

# Reduced step size
sample(gdemo([1.5, 2]), HMC(0.01, 10), 1000)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/hmc.jl#L32-L61">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.HMCDA"><a class="docstring-binding" href="#Turing.Inference.HMCDA"><code>Turing.Inference.HMCDA</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">HMCDA(
    n_adapts::Int, δ::Float64, λ::Float64; ϵ::Float64 = 0.0;
    adtype::ADTypes.AbstractADType = AutoForwardDiff(),
)</code></pre><p>Hamiltonian Monte Carlo sampler with Dual Averaging algorithm.</p><p><strong>Usage</strong></p><pre><code class="language-julia hljs">HMCDA(200, 0.65, 0.3)</code></pre><p><strong>Arguments</strong></p><ul><li><code>n_adapts</code>: Numbers of samples to use for adaptation.</li><li><code>δ</code>: Target acceptance rate. 65% is often recommended.</li><li><code>λ</code>: Target leapfrog length.</li><li><code>ϵ</code>: Initial step size; 0 means automatically search by Turing.</li><li><code>adtype</code>: The automatic differentiation (AD) backend.   If not specified, <code>ForwardDiff</code> is used, with its <code>chunksize</code> automatically determined.</li></ul><p><strong>Reference</strong></p><p>For more information, please view the following paper (<a href="https://arxiv.org/abs/1111.4246">arXiv link</a>):</p><p>Hoffman, Matthew D., and Andrew Gelman. &quot;The No-U-turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.&quot; Journal of Machine Learning Research 15, no. 1 (2014): 1593-1623.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/hmc.jl#L291-L321">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.IS"><a class="docstring-binding" href="#Turing.Inference.IS"><code>Turing.Inference.IS</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">IS()</code></pre><p>Importance sampling algorithm.</p><p>Usage:</p><pre><code class="language-julia hljs">IS()</code></pre><p>Example:</p><pre><code class="language-julia hljs"># Define a simple Normal model with unknown mean and variance.
@model function gdemo(x)
    s² ~ InverseGamma(2,3)
    m ~ Normal(0,sqrt.(s))
    x[1] ~ Normal(m, sqrt.(s))
    x[2] ~ Normal(m, sqrt.(s))
    return s², m
end

sample(gdemo([1.5, 2]), IS(), 1000)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/is.jl#L1-L26">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.MH"><a class="docstring-binding" href="#Turing.Inference.MH"><code>Turing.Inference.MH</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">MH(proposals...)</code></pre><p>Construct a Metropolis-Hastings algorithm.</p><p>The arguments <code>proposals</code> can be</p><ul><li>Blank (i.e. <code>MH()</code>), in which case <code>MH</code> defaults to using the prior for each parameter as the proposal distribution.</li><li>An iterable of pairs or tuples mapping a <code>Symbol</code> to a <code>AdvancedMH.Proposal</code>, <code>Distribution</code>, or <code>Function</code> that returns a conditional proposal distribution.</li><li>A covariance matrix to use as for mean-zero multivariate normal proposals.</li></ul><p><strong>Examples</strong></p><p>The default <code>MH</code> will draw proposal samples from the prior distribution using <code>AdvancedMH.StaticProposal</code>.</p><pre><code class="language-julia hljs">@model function gdemo(x, y)
    s² ~ InverseGamma(2,3)
    m ~ Normal(0, sqrt(s²))
    x ~ Normal(m, sqrt(s²))
    y ~ Normal(m, sqrt(s²))
end

chain = sample(gdemo(1.5, 2.0), MH(), 1_000)
mean(chain)</code></pre><p>Specifying a single distribution implies the use of static MH:</p><pre><code class="language-julia hljs"># Use a static proposal for s² (which happens to be the same
# as the prior) and a static proposal for m (note that this
# isn&#39;t a random walk proposal).
chain = sample(
    gdemo(1.5, 2.0),
    MH(
        :s² =&gt; InverseGamma(2, 3),
        :m =&gt; Normal(0, 1)
    ),
    1_000
)
mean(chain)</code></pre><p>Specifying explicit proposals using the <code>AdvancedMH</code> interface:</p><pre><code class="language-julia hljs"># Use a static proposal for s² and random walk with proposal
# standard deviation of 0.25 for m.
chain = sample(
    gdemo(1.5, 2.0),
    MH(
        :s² =&gt; AdvancedMH.StaticProposal(InverseGamma(2,3)),
        :m =&gt; AdvancedMH.RandomWalkProposal(Normal(0, 0.25))
    ),
    1_000
)
mean(chain)</code></pre><p>Using a custom function to specify a conditional distribution:</p><pre><code class="language-julia hljs"># Use a static proposal for s and and a conditional proposal for m,
# where the proposal is centered around the current sample.
chain = sample(
    gdemo(1.5, 2.0),
    MH(
        :s² =&gt; InverseGamma(2, 3),
        :m =&gt; x -&gt; Normal(x, 1)
    ),
    1_000
)
mean(chain)</code></pre><p>Providing a covariance matrix will cause <code>MH</code> to perform random-walk sampling in the transformed space with proposals drawn from a multivariate normal distribution. The provided matrix must be positive semi-definite and square:</p><pre><code class="language-julia hljs"># Providing a custom variance-covariance matrix
chain = sample(
    gdemo(1.5, 2.0),
    MH(
        [0.25 0.05;
         0.05 0.50]
    ),
    1_000
)
mean(chain)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/mh.jl#L11-L106">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.MHState"><a class="docstring-binding" href="#Turing.Inference.MHState"><code>Turing.Inference.MHState</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">MHState(varinfo::AbstractVarInfo, logjoint_internal::Real)</code></pre><p>State for Metropolis-Hastings sampling.</p><p><code>varinfo</code> must have the correct parameters set inside it, but its other fields (e.g. accumulators, which track logp) can in general be missing or incorrect.</p><p><code>logjoint_internal</code> is the log joint probability of the model, evaluated using the parameters and linking status of <code>varinfo</code>. It should be equal to <code>DynamicPPL.getlogjoint_internal(varinfo)</code>. This information is returned by the MH sampler so we store this here to avoid re-evaluating the model unnecessarily.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/mh.jl#L156-L169">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.NUTS"><a class="docstring-binding" href="#Turing.Inference.NUTS"><code>Turing.Inference.NUTS</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">NUTS(n_adapts::Int, δ::Float64; max_depth::Int=10, Δ_max::Float64=1000.0, init_ϵ::Float64=0.0; adtype::ADTypes.AbstractADType=AutoForwardDiff()</code></pre><p>No-U-Turn Sampler (NUTS) sampler.</p><p>Usage:</p><pre><code class="language-julia hljs">NUTS()            # Use default NUTS configuration.
NUTS(1000, 0.65)  # Use 1000 adaption steps, and target accept ratio 0.65.</code></pre><p>Arguments:</p><ul><li><code>n_adapts::Int</code> : The number of samples to use with adaptation.</li><li><code>δ::Float64</code> : Target acceptance rate for dual averaging.</li><li><code>max_depth::Int</code> : Maximum doubling tree depth.</li><li><code>Δ_max::Float64</code> : Maximum divergence during doubling tree.</li><li><code>init_ϵ::Float64</code> : Initial step size; 0 means automatically searching using a heuristic procedure.</li><li><code>adtype::ADTypes.AbstractADType</code> : The automatic differentiation (AD) backend.   If not specified, <code>ForwardDiff</code> is used, with its <code>chunksize</code> automatically determined.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/hmc.jl#L366-L388">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.OldLogDensityFunction"><a class="docstring-binding" href="#Turing.Inference.OldLogDensityFunction"><code>Turing.Inference.OldLogDensityFunction</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">OldLogDensityFunction</code></pre><p>This is a clone of pre-0.39 DynamicPPL.LogDensityFunction. It is needed for MH because MH doesn&#39;t actually obey the LogDensityProblems.jl interface: it evaluates &#39;LogDensityFunctions&#39; with a NamedTuple(!!)</p><p>This means that we can&#39;t <em>really</em> use DynamicPPL&#39;s LogDensityFunction, since that only promises to obey the interface of being called with a vector.</p><p>In particular, because <code>set_namedtuple!</code> acts on a VarInfo, we need to store the VarInfo inside this struct (which DynamicPPL&#39;s LogDensityFunction no longer does).</p><p>This SHOULD really be refactored to remove this requirement.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/mh.jl#L181-L195">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.PG"><a class="docstring-binding" href="#Turing.Inference.PG"><code>Turing.Inference.PG</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">struct PG{R} &lt;: Turing.Inference.ParticleInference</code></pre><p>Particle Gibbs sampler.</p><p><strong>Fields</strong></p><ul><li><p><code>nparticles::Int64</code>: Number of particles.</p></li><li><p><code>resampler::Any</code>: Resampling algorithm.</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/particle_mcmc.jl#L202">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.PG-Tuple{Int64}"><a class="docstring-binding" href="#Turing.Inference.PG-Tuple{Int64}"><code>Turing.Inference.PG</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>PG(n, [resampler = AdvancedPS.ResampleWithESSThreshold()]) PG(n, [resampler = AdvancedPS.resample_systematic, ]threshold)</p><p>Create a Particle Gibbs sampler of type <a href="#Turing.Inference.PG"><code>PG</code></a> with <code>n</code> particles.</p><p>If the algorithm for the resampling step is not specified explicitly, systematic resampling is performed if the estimated effective sample size per particle drops below 0.5.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/particle_mcmc.jl#L218-L226">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.PolynomialStepsize-Union{Tuple{T}, Tuple{T, T, T}} where T&lt;:Real"><a class="docstring-binding" href="#Turing.Inference.PolynomialStepsize-Union{Tuple{T}, Tuple{T, T, T}} where T&lt;:Real"><code>Turing.Inference.PolynomialStepsize</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">PolynomialStepsize(a[, b=0, γ=0.55])</code></pre><p>Create a polynomially decaying stepsize function.</p><p>At iteration <code>t</code>, the step size is</p><p class="math-container">\[a (b + t)^{-γ}.\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/sghmc.jl#L130-L139">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.Prior"><a class="docstring-binding" href="#Turing.Inference.Prior"><code>Turing.Inference.Prior</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">Prior()</code></pre><p>Algorithm for sampling from the prior.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/prior.jl#L1-L5">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.ProduceLogLikelihoodAccumulator"><a class="docstring-binding" href="#Turing.Inference.ProduceLogLikelihoodAccumulator"><code>Turing.Inference.ProduceLogLikelihoodAccumulator</code></a> — <span class="docstring-category">Type</span></summary><section><div><p>ProduceLogLikelihoodAccumulator{T&lt;:Real} &lt;: AbstractAccumulator</p><p>Exactly like <code>LogLikelihoodAccumulator</code>, but calls <code>Libtask.produce</code> on change of value.</p><p><strong>Fields</strong></p><ul><li><code>logp::Real</code>: the scalar log likelihood value</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/particle_mcmc.jl#L457-L464">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.RepeatSampler"><a class="docstring-binding" href="#Turing.Inference.RepeatSampler"><code>Turing.Inference.RepeatSampler</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">RepeatSampler &lt;: AbstractMCMC.AbstractSampler</code></pre><p>A <code>RepeatSampler</code> is a container for a sampler and a number of times to repeat it.</p><p><strong>Fields</strong></p><ul><li><p><code>sampler</code>: The sampler to repeat</p></li><li><p><code>num_repeat</code>: The number of times to repeat the sampler</p></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">repeated_sampler = RepeatSampler(sampler, 10)
AbstractMCMC.step(rng, model, repeated_sampler) # take 10 steps of `sampler`</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/repeat_sampler.jl#L1-L14">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.SGHMC"><a class="docstring-binding" href="#Turing.Inference.SGHMC"><code>Turing.Inference.SGHMC</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">SGHMC{AD}</code></pre><p>Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) sampler.</p><p><strong>Fields</strong></p><ul><li><p><code>learning_rate::Real</code></p></li><li><p><code>momentum_decay::Real</code></p></li><li><p><code>adtype::Any</code></p></li></ul><p><strong>Reference</strong></p><p>Tianqi Chen, Emily Fox, &amp; Carlos Guestrin (2014). Stochastic Gradient Hamiltonian Monte Carlo. In: Proceedings of the 31st International Conference on Machine Learning (pp. 1683–1691).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/sghmc.jl#L1-L14">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.SGHMC-Tuple{}"><a class="docstring-binding" href="#Turing.Inference.SGHMC-Tuple{}"><code>Turing.Inference.SGHMC</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">SGHMC(;
    learning_rate::Real,
    momentum_decay::Real,
    adtype::ADTypes.AbstractADType = AutoForwardDiff(),
)</code></pre><p>Create a Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) sampler.</p><p>If the automatic differentiation (AD) backend <code>adtype</code> is not provided, ForwardDiff with automatically determined <code>chunksize</code> is used.</p><p><strong>Reference</strong></p><p>Tianqi Chen, Emily Fox, &amp; Carlos Guestrin (2014). Stochastic Gradient Hamiltonian Monte Carlo. In: Proceedings of the 31st International Conference on Machine Learning (pp. 1683–1691).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/sghmc.jl#L21-L38">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.SGLD"><a class="docstring-binding" href="#Turing.Inference.SGLD"><code>Turing.Inference.SGLD</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">SGLD</code></pre><p>Stochastic gradient Langevin dynamics (SGLD) sampler.</p><p><strong>Fields</strong></p><ul><li><p><code>stepsize::Any</code>: Step size function.</p></li><li><p><code>adtype::Any</code></p></li></ul><p><strong>Reference</strong></p><p>Max Welling &amp; Yee Whye Teh (2011). Bayesian Learning via Stochastic Gradient Langevin Dynamics. In: Proceedings of the 28th International Conference on Machine Learning (pp. 681–688).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/sghmc.jl#L96-L109">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.SGLD-Tuple{}"><a class="docstring-binding" href="#Turing.Inference.SGLD-Tuple{}"><code>Turing.Inference.SGLD</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">SGLD(;
    stepsize = PolynomialStepsize(0.01),
    adtype::ADTypes.AbstractADType = AutoForwardDiff(),
)</code></pre><p>Stochastic gradient Langevin dynamics (SGLD) sampler.</p><p>By default, a polynomially decaying stepsize is used.</p><p>If the automatic differentiation (AD) backend <code>adtype</code> is not provided, ForwardDiff with automatically determined <code>chunksize</code> is used.</p><p><strong>Reference</strong></p><p>Max Welling &amp; Yee Whye Teh (2011). Bayesian Learning via Stochastic Gradient Langevin Dynamics. In: Proceedings of the 28th International Conference on Machine Learning (pp. 681–688).</p><p>See also: <a href="#Turing.Inference.PolynomialStepsize-Union{Tuple{T}, Tuple{T, T, T}} where T&lt;:Real"><code>PolynomialStepsize</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/sghmc.jl#L149-L169">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.SMC"><a class="docstring-binding" href="#Turing.Inference.SMC"><code>Turing.Inference.SMC</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">struct SMC{R} &lt;: Turing.Inference.ParticleInference</code></pre><p>Sequential Monte Carlo sampler.</p><p><strong>Fields</strong></p><ul><li><code>resampler::Any</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/particle_mcmc.jl#L75">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.SMC-Tuple{}"><a class="docstring-binding" href="#Turing.Inference.SMC-Tuple{}"><code>Turing.Inference.SMC</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>SMC([resampler = AdvancedPS.ResampleWithESSThreshold()]) SMC([resampler = AdvancedPS.resample_systematic, ]threshold)</p><p>Create a sequential Monte Carlo sampler of type <a href="#Turing.Inference.SMC"><code>SMC</code></a>.</p><p>If the algorithm for the resampling step is not specified explicitly, systematic resampling is performed if the estimated effective sample size per particle drops below 0.5.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/particle_mcmc.jl#L88-L96">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.build_variable_dict-Tuple{DynamicPPL.Model}"><a class="docstring-binding" href="#Turing.Inference.build_variable_dict-Tuple{DynamicPPL.Model}"><code>Turing.Inference.build_variable_dict</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">build_variable_dict(model::DynamicPPL.Model)</code></pre><p>Traverse the context stack of <code>model</code> and build a <code>Dict</code> of all the variable values that are set in GibbsContext, ConditionContext, or FixedContext.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/gibbs_conditional.jl#L84-L89">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.default_varinfo-Tuple{Random.AbstractRNG, DynamicPPL.Model, AbstractMCMC.AbstractSampler}"><a class="docstring-binding" href="#Turing.Inference.default_varinfo-Tuple{Random.AbstractRNG, DynamicPPL.Model, AbstractMCMC.AbstractSampler}"><code>Turing.Inference.default_varinfo</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">default_varinfo(rng, model, sampler)</code></pre><p>Return a default varinfo object for the given <code>model</code> and <code>sampler</code>. The default method for this returns a NTVarInfo (i.e. &#39;typed varinfo&#39;).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/abstractmcmc.jl#L22-L27">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.dist_val_tuple-Tuple{MH, Union{DynamicPPL.ThreadSafeVarInfo{&lt;:DynamicPPL.VarInfo{Tmeta}}, DynamicPPL.VarInfo{Tmeta}} where Tmeta}"><a class="docstring-binding" href="#Turing.Inference.dist_val_tuple-Tuple{MH, Union{DynamicPPL.ThreadSafeVarInfo{&lt;:DynamicPPL.VarInfo{Tmeta}}, DynamicPPL.VarInfo{Tmeta}} where Tmeta}"><code>Turing.Inference.dist_val_tuple</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">dist_val_tuple(spl::MH, vi::VarInfo)</code></pre><p>Return two <code>NamedTuples</code>.</p><p>The first <code>NamedTuple</code> has symbols as keys and distributions as values. The second <code>NamedTuple</code> has model symbols as keys and their stored values as values.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/mh.jl#L272-L279">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.externalsampler-Tuple{AbstractMCMC.AbstractSampler}"><a class="docstring-binding" href="#Turing.Inference.externalsampler-Tuple{AbstractMCMC.AbstractSampler}"><code>Turing.Inference.externalsampler</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">externalsampler(
    sampler::AbstractSampler;
    adtype=AutoForwardDiff(),
    unconstrained=AbstractMCMC.requires_unconstrained_space(sampler),
)</code></pre><p>Wrap a sampler so it can be used as an inference algorithm.</p><p><strong>Arguments</strong></p><ul><li><code>sampler::AbstractSampler</code>: The sampler to wrap.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>adtype::ADTypes.AbstractADType=ADTypes.AutoForwardDiff()</code>: The automatic differentiation (AD) backend to use.</li><li><code>unconstrained::Bool=AbstractMCMC.requires_unconstrained_space(sampler)</code>: Whether the sampler requires unconstrained space.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/external_sampler.jl#L98-L115">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.get_trace_local_resampled_maybe-Tuple{Bool}"><a class="docstring-binding" href="#Turing.Inference.get_trace_local_resampled_maybe-Tuple{Bool}"><code>Turing.Inference.get_trace_local_resampled_maybe</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>get<em>trace</em>local<em>resampled</em>maybe(fallback_resampled::Bool)</p><p>Get the <code>Trace</code> local <code>resampled</code> if one exists.</p><p>If executed within a <code>TapedTask</code>, return the <code>resampled</code> stored in the &quot;taped globals&quot; of the task, otherwise return <code>fallback_resampled</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/particle_mcmc.jl#L342-L349">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.get_trace_local_rng_maybe-Tuple{Random.AbstractRNG}"><a class="docstring-binding" href="#Turing.Inference.get_trace_local_rng_maybe-Tuple{Random.AbstractRNG}"><code>Turing.Inference.get_trace_local_rng_maybe</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>get<em>trace</em>local<em>rng</em>maybe(rng::Random.AbstractRNG)</p><p>Get the <code>Trace</code> local rng if one exists.</p><p>If executed within a <code>TapedTask</code>, return the <code>rng</code> stored in the &quot;taped globals&quot; of the task, otherwise return <code>vi</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/particle_mcmc.jl#L359-L366">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.get_trace_local_varinfo_maybe-Tuple{DynamicPPL.AbstractVarInfo}"><a class="docstring-binding" href="#Turing.Inference.get_trace_local_varinfo_maybe-Tuple{DynamicPPL.AbstractVarInfo}"><code>Turing.Inference.get_trace_local_varinfo_maybe</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>get<em>trace</em>local<em>varinfo</em>maybe(vi::AbstractVarInfo)</p><p>Get the <code>Trace</code> local varinfo if one exists.</p><p>If executed within a <code>TapedTask</code>, return the <code>varinfo</code> stored in the &quot;taped globals&quot; of the task, otherwise return <code>vi</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/particle_mcmc.jl#L325-L332">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.gibbs_initialstep_recursive"><a class="docstring-binding" href="#Turing.Inference.gibbs_initialstep_recursive"><code>Turing.Inference.gibbs_initialstep_recursive</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Take the first step of MCMC for the first component sampler, and call the same function recursively on the remaining samplers, until no samplers remain. Return the global VarInfo and a tuple of initial states for all component samplers.</p><p>The <code>step_function</code> argument should always be either AbstractMCMC.step or AbstractMCMC.step_warmup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/gibbs.jl#L359-L366">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.gibbs_step_recursive"><a class="docstring-binding" href="#Turing.Inference.gibbs_step_recursive"><code>Turing.Inference.gibbs_step_recursive</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Run a Gibbs step for the first varname/sampler/state tuple, and recursively call the same function on the tail, until there are no more samplers left.</p><p>The <code>step_function</code> argument should always be either AbstractMCMC.step or AbstractMCMC.step_warmup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/gibbs.jl#L566-L572">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.init_strategy-Tuple{AbstractMCMC.AbstractSampler}"><a class="docstring-binding" href="#Turing.Inference.init_strategy-Tuple{AbstractMCMC.AbstractSampler}"><code>Turing.Inference.init_strategy</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">Turing.Inference.init_strategy(spl::AbstractSampler)</code></pre><p>Get the default initialization strategy for a given sampler <code>spl</code>, i.e. how initial parameters for sampling are chosen if not specified by the user. By default, this is <code>InitFromPrior()</code>, which samples initial parameters from the prior distribution.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/abstractmcmc.jl#L13-L19">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.initial_varinfo-Tuple{Any, Any, Any, DynamicPPL.AbstractInitStrategy}"><a class="docstring-binding" href="#Turing.Inference.initial_varinfo-Tuple{Any, Any, Any, DynamicPPL.AbstractInitStrategy}"><code>Turing.Inference.initial_varinfo</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Initialise a VarInfo for the Gibbs sampler.</p><p>This is straight up copypasta from DynamicPPL&#39;s src/sampler.jl. It is repeated here to support calling both step and step<em>warmup as the initial step. DynamicPPL initialstep is incompatible with step</em>warmup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/gibbs.jl#L298-L304">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.isgibbscomponent-Tuple{AbstractMCMC.AbstractSampler}"><a class="docstring-binding" href="#Turing.Inference.isgibbscomponent-Tuple{AbstractMCMC.AbstractSampler}"><code>Turing.Inference.isgibbscomponent</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">isgibbscomponent(spl::AbstractSampler)</code></pre><p>Return a boolean indicating whether <code>spl</code> is a valid component for a Gibbs sampler.</p><p>Defaults to <code>true</code> if no method has been defined for a particular sampler.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/gibbs.jl#L1-L7">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.loadstate-Tuple{Chains}"><a class="docstring-binding" href="#Turing.Inference.loadstate-Tuple{Chains}"><code>Turing.Inference.loadstate</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">loadstate(chain::MCMCChains.Chains)</code></pre><p>Load the final state of the sampler from a <code>MCMCChains.Chains</code> object.</p><p>To save the final state of the sampler, you must use <code>sample(...; save_state=true)</code>. If this argument was not used during sampling, calling <code>loadstate</code> will throw an error.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/abstractmcmc.jl#L118-L125">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.make_conditional-Tuple{DynamicPPL.Model, AbstractVector{&lt;:AbstractPPL.VarName}, Any}"><a class="docstring-binding" href="#Turing.Inference.make_conditional-Tuple{DynamicPPL.Model, AbstractVector{&lt;:AbstractPPL.VarName}, Any}"><code>Turing.Inference.make_conditional</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">make_conditional(model, target_variables, varinfo)</code></pre><p>Return a new, conditioned model for a component of a Gibbs sampler.</p><p><strong>Arguments</strong></p><ul><li><code>model::DynamicPPL.Model</code>: The model to condition.</li><li><code>target_variables::AbstractVector{&lt;:VarName}</code>: The target variables of the component</li></ul><p>sampler. These will <em>not</em> be conditioned.</p><ul><li><code>varinfo::DynamicPPL.AbstractVarInfo</code>: Values for all variables in the model. All the</li></ul><p>values in <code>varinfo</code> but not in <code>target_variables</code> will be conditioned to the values they have in <code>varinfo</code>.</p><p><strong>Returns</strong></p><ul><li>A new model with the variables <em>not</em> in <code>target_variables</code> conditioned.</li><li>The <code>GibbsContext</code> object that will be used to condition the variables. This is necessary</li></ul><p>because evaluation can mutate its <code>global_varinfo</code> field, which we need to access later.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/gibbs.jl#L202-L219">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.match_linking!!-Tuple{Any, Any, Any}"><a class="docstring-binding" href="#Turing.Inference.match_linking!!-Tuple{Any, Any, Any}"><code>Turing.Inference.match_linking!!</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">match_linking!!(varinfo_local, prev_state_local, model)</code></pre><p>Make sure the linked/invlinked status of varinfo_local matches that of the previous state for this sampler. This is relevant when multiple samplers are sampling the same variables, and one might need it to be linked while the other doesn&#39;t.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/gibbs.jl#L522-L528">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.mh_accept-Tuple{Real, Real, Real}"><a class="docstring-binding" href="#Turing.Inference.mh_accept-Tuple{Real, Real, Real}"><code>Turing.Inference.mh_accept</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">mh_accept(logp_current::Real, logp_proposal::Real, log_proposal_ratio::Real)</code></pre><p>Decide if a proposal <span>$x&#39;$</span> with log probability <span>$\log p(x&#39;) = logp_proposal$</span> and log proposal ratio <span>$\log k(x&#39;, x) - \log k(x, x&#39;) = log_proposal_ratio$</span> in a Metropolis-Hastings algorithm with Markov kernel <span>$k(x_t, x_{t+1})$</span> and current state <span>$x$</span> with log probability <span>$\log p(x) = logp_current$</span> is accepted by evaluating the Metropolis-Hastings acceptance criterion</p><p class="math-container">\[\log U \leq \log p(x&#39;) - \log p(x) + \log k(x&#39;, x) - \log k(x, x&#39;)\]</p><p>for a uniform random number <span>$U \in [0, 1)$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/Inference.jl#L100-L112">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.set_namedtuple!-Tuple{Union{DynamicPPL.ThreadSafeVarInfo{&lt;:DynamicPPL.VarInfo{Tmeta}}, DynamicPPL.VarInfo{Tmeta}} where Tmeta, NamedTuple}"><a class="docstring-binding" href="#Turing.Inference.set_namedtuple!-Tuple{Union{DynamicPPL.ThreadSafeVarInfo{&lt;:DynamicPPL.VarInfo{Tmeta}}, DynamicPPL.VarInfo{Tmeta}} where Tmeta, NamedTuple}"><code>Turing.Inference.set_namedtuple!</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">set_namedtuple!(vi::VarInfo, nt::NamedTuple)</code></pre><p>Places the values of a <code>NamedTuple</code> into the relevant places of a <code>VarInfo</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/mh.jl#L229-L233">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.set_trace_local_varinfo_maybe-Tuple{DynamicPPL.AbstractVarInfo}"><a class="docstring-binding" href="#Turing.Inference.set_trace_local_varinfo_maybe-Tuple{DynamicPPL.AbstractVarInfo}"><code>Turing.Inference.set_trace_local_varinfo_maybe</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>set<em>trace</em>local<em>varinfo</em>maybe(vi::AbstractVarInfo)</p><p>Set the <code>Trace</code> local varinfo if executing within a <code>Trace</code>. Return <code>nothing</code>.</p><p>If executed within a <code>TapedTask</code>, set the <code>varinfo</code> stored in the &quot;taped globals&quot; of the task. Otherwise do nothing.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/particle_mcmc.jl#L375-L382">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Turing.Inference.setparams_varinfo!!-Tuple{DynamicPPL.Model, AbstractMCMC.AbstractSampler, Any, DynamicPPL.AbstractVarInfo}"><a class="docstring-binding" href="#Turing.Inference.setparams_varinfo!!-Tuple{DynamicPPL.Model, AbstractMCMC.AbstractSampler, Any, DynamicPPL.AbstractVarInfo}"><code>Turing.Inference.setparams_varinfo!!</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">setparams_varinfo!!(model::DynamicPPL.Model, sampler::AbstractSampler, state, params::AbstractVarInfo)</code></pre><p>A lot like AbstractMCMC.setparams!!, but instead of taking a vector of parameters, takes an <code>AbstractVarInfo</code> object. Also takes the <code>sampler</code> as an argument. By default, falls back to <code>AbstractMCMC.setparams!!(model, state, params[:])</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/fef2e01c075b2d2ddccb309be7c7bf555af9624a/src/mcmc/gibbs.jl#L458-L464">source</a></section></details></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« API</a><a class="docs-footer-nextpage" href="../Optimisation/">Optimisation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Monday 26 January 2026 02:14">Monday 26 January 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
